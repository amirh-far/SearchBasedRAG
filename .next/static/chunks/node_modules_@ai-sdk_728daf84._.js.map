{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 7, "column": 0}, "map": {"version":3,"sources":["file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/openai-compatible/src/openai-compatible-chat-language-model.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/openai-compatible/src/convert-to-openai-compatible-chat-messages.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/openai-compatible/src/get-response-metadata.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/openai-compatible/src/map-openai-compatible-finish-reason.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/openai-compatible/src/openai-compatible-error.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/openai-compatible/src/openai-compatible-prepare-tools.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/openai-compatible/src/openai-compatible-completion-language-model.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/openai-compatible/src/convert-to-openai-compatible-completion-prompt.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/openai-compatible/src/openai-compatible-embedding-model.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/openai-compatible/src/openai-compatible-provider.ts"],"sourcesContent":["import {\n  APICallError,\n  InvalidResponseDataError,\n  LanguageModelV1,\n  LanguageModelV1CallWarning,\n  LanguageModelV1FinishReason,\n  LanguageModelV1ObjectGenerationMode,\n  LanguageModelV1StreamPart,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonErrorResponseHandler,\n  createJsonResponseHandler,\n  FetchFunction,\n  generateId,\n  isParsableJson,\n  ParseResult,\n  postJsonToApi,\n  ResponseHandler,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\nimport { convertToOpenAICompatibleChatMessages } from './convert-to-openai-compatible-chat-messages';\nimport { getResponseMetadata } from './get-response-metadata';\nimport { mapOpenAICompatibleFinishReason } from './map-openai-compatible-finish-reason';\nimport {\n  OpenAICompatibleChatModelId,\n  OpenAICompatibleChatSettings,\n} from './openai-compatible-chat-settings';\nimport {\n  defaultOpenAICompatibleErrorStructure,\n  ProviderErrorStructure,\n} from './openai-compatible-error';\nimport { prepareTools } from './openai-compatible-prepare-tools';\nimport { MetadataExtractor } from './openai-compatible-metadata-extractor';\n\nexport type OpenAICompatibleChatConfig = {\n  provider: string;\n  headers: () => Record<string, string | undefined>;\n  url: (options: { modelId: string; path: string }) => string;\n  fetch?: FetchFunction;\n  errorStructure?: ProviderErrorStructure<any>;\n  metadataExtractor?: MetadataExtractor;\n\n  /**\nDefault object generation mode that should be used with this model when\nno mode is specified. Should be the mode with the best results for this\nmodel. `undefined` can be specified if object generation is not supported.\n  */\n  defaultObjectGenerationMode?: LanguageModelV1ObjectGenerationMode;\n\n  /**\n   * Whether the model supports structured outputs.\n   */\n  supportsStructuredOutputs?: boolean;\n};\n\nexport class OpenAICompatibleChatLanguageModel implements LanguageModelV1 {\n  readonly specificationVersion = 'v1';\n\n  readonly supportsStructuredOutputs: boolean;\n\n  readonly modelId: OpenAICompatibleChatModelId;\n  readonly settings: OpenAICompatibleChatSettings;\n\n  private readonly config: OpenAICompatibleChatConfig;\n  private readonly failedResponseHandler: ResponseHandler<APICallError>;\n  private readonly chunkSchema; // type inferred via constructor\n\n  constructor(\n    modelId: OpenAICompatibleChatModelId,\n    settings: OpenAICompatibleChatSettings,\n    config: OpenAICompatibleChatConfig,\n  ) {\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n\n    // initialize error handling:\n    const errorStructure =\n      config.errorStructure ?? defaultOpenAICompatibleErrorStructure;\n    this.chunkSchema = createOpenAICompatibleChatChunkSchema(\n      errorStructure.errorSchema,\n    );\n    this.failedResponseHandler = createJsonErrorResponseHandler(errorStructure);\n\n    this.supportsStructuredOutputs = config.supportsStructuredOutputs ?? false;\n  }\n\n  get defaultObjectGenerationMode(): 'json' | 'tool' | undefined {\n    return this.config.defaultObjectGenerationMode;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private getArgs({\n    mode,\n    prompt,\n    maxTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences,\n    responseFormat,\n    seed,\n  }: Parameters<LanguageModelV1['doGenerate']>[0]) {\n    const type = mode.type;\n\n    const warnings: LanguageModelV1CallWarning[] = [];\n\n    if (topK != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'topK',\n      });\n    }\n\n    if (\n      responseFormat?.type === 'json' &&\n      responseFormat.schema != null &&\n      !this.supportsStructuredOutputs\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'responseFormat',\n        details:\n          'JSON response format schema is only supported with structuredOutputs',\n      });\n    }\n\n    const baseArgs = {\n      // model id:\n      model: this.modelId,\n\n      // model specific settings:\n      user: this.settings.user,\n\n      // standardized settings:\n      max_tokens: maxTokens,\n      temperature,\n      top_p: topP,\n      frequency_penalty: frequencyPenalty,\n      presence_penalty: presencePenalty,\n      response_format:\n        responseFormat?.type === 'json'\n          ? this.supportsStructuredOutputs === true &&\n            responseFormat.schema != null\n            ? {\n                type: 'json_schema',\n                json_schema: {\n                  schema: responseFormat.schema,\n                  name: responseFormat.name ?? 'response',\n                  description: responseFormat.description,\n                },\n              }\n            : { type: 'json_object' }\n          : undefined,\n\n      stop: stopSequences,\n      seed,\n\n      // messages:\n      messages: convertToOpenAICompatibleChatMessages(prompt),\n    };\n\n    switch (type) {\n      case 'regular': {\n        const { tools, tool_choice, toolWarnings } = prepareTools({\n          mode,\n          structuredOutputs: this.supportsStructuredOutputs,\n        });\n\n        return {\n          args: { ...baseArgs, tools, tool_choice },\n          warnings: [...warnings, ...toolWarnings],\n        };\n      }\n\n      case 'object-json': {\n        return {\n          args: {\n            ...baseArgs,\n            response_format:\n              this.supportsStructuredOutputs === true && mode.schema != null\n                ? {\n                    type: 'json_schema',\n                    json_schema: {\n                      schema: mode.schema,\n                      name: mode.name ?? 'response',\n                      description: mode.description,\n                    },\n                  }\n                : { type: 'json_object' },\n          },\n          warnings,\n        };\n      }\n\n      case 'object-tool': {\n        return {\n          args: {\n            ...baseArgs,\n            tool_choice: {\n              type: 'function',\n              function: { name: mode.tool.name },\n            },\n            tools: [\n              {\n                type: 'function',\n                function: {\n                  name: mode.tool.name,\n                  description: mode.tool.description,\n                  parameters: mode.tool.parameters,\n                },\n              },\n            ],\n          },\n          warnings,\n        };\n      }\n\n      default: {\n        const _exhaustiveCheck: never = type;\n        throw new Error(`Unsupported type: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV1['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV1['doGenerate']>>> {\n    const { args, warnings } = this.getArgs({ ...options });\n\n    const body = JSON.stringify(args);\n\n    const {\n      responseHeaders,\n      value: responseBody,\n      rawValue: parsedBody,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/chat/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: args,\n      failedResponseHandler: this.failedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        OpenAICompatibleChatResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const { messages: rawPrompt, ...rawSettings } = args;\n    const choice = responseBody.choices[0];\n    const providerMetadata = this.config.metadataExtractor?.extractMetadata?.({\n      parsedBody,\n    });\n\n    return {\n      text: choice.message.content ?? undefined,\n      reasoning: choice.message.reasoning_content ?? undefined,\n      toolCalls: choice.message.tool_calls?.map(toolCall => ({\n        toolCallType: 'function',\n        toolCallId: toolCall.id ?? generateId(),\n        toolName: toolCall.function.name,\n        args: toolCall.function.arguments!,\n      })),\n      finishReason: mapOpenAICompatibleFinishReason(choice.finish_reason),\n      usage: {\n        promptTokens: responseBody.usage?.prompt_tokens ?? NaN,\n        completionTokens: responseBody.usage?.completion_tokens ?? NaN,\n      },\n      ...(providerMetadata && { providerMetadata }),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      response: getResponseMetadata(responseBody),\n      warnings,\n      request: { body },\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV1['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV1['doStream']>>> {\n    if (this.settings.simulateStreaming) {\n      const result = await this.doGenerate(options);\n      const simulatedStream = new ReadableStream<LanguageModelV1StreamPart>({\n        start(controller) {\n          controller.enqueue({ type: 'response-metadata', ...result.response });\n          if (result.reasoning) {\n            controller.enqueue({\n              type: 'reasoning',\n              textDelta: result.reasoning,\n            });\n          }\n          if (result.text) {\n            controller.enqueue({\n              type: 'text-delta',\n              textDelta: result.text,\n            });\n          }\n          if (result.toolCalls) {\n            for (const toolCall of result.toolCalls) {\n              controller.enqueue({\n                type: 'tool-call',\n                ...toolCall,\n              });\n            }\n          }\n          controller.enqueue({\n            type: 'finish',\n            finishReason: result.finishReason,\n            usage: result.usage,\n            logprobs: result.logprobs,\n            providerMetadata: result.providerMetadata,\n          });\n          controller.close();\n        },\n      });\n      return {\n        stream: simulatedStream,\n        rawCall: result.rawCall,\n        rawResponse: result.rawResponse,\n        warnings: result.warnings,\n      };\n    }\n\n    const { args, warnings } = this.getArgs({ ...options });\n\n    const body = JSON.stringify({ ...args, stream: true });\n    const metadataExtractor =\n      this.config.metadataExtractor?.createStreamExtractor();\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/chat/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: {\n        ...args,\n        stream: true,\n      },\n      failedResponseHandler: this.failedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        this.chunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const { messages: rawPrompt, ...rawSettings } = args;\n\n    const toolCalls: Array<{\n      id: string;\n      type: 'function';\n      function: {\n        name: string;\n        arguments: string;\n      };\n      hasFinished: boolean;\n    }> = [];\n\n    let finishReason: LanguageModelV1FinishReason = 'unknown';\n    let usage: {\n      promptTokens: number | undefined;\n      completionTokens: number | undefined;\n    } = {\n      promptTokens: undefined,\n      completionTokens: undefined,\n    };\n    let isFirstChunk = true;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<z.infer<typeof this.chunkSchema>>,\n          LanguageModelV1StreamPart\n        >({\n          // TODO we lost type safety on Chunk, most likely due to the error schema. MUST FIX\n          transform(chunk, controller) {\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n            const value = chunk.value;\n\n            metadataExtractor?.processChunk(chunk.rawValue);\n\n            // handle error chunks:\n            if ('error' in value) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: value.error.message });\n              return;\n            }\n\n            if (isFirstChunk) {\n              isFirstChunk = false;\n\n              controller.enqueue({\n                type: 'response-metadata',\n                ...getResponseMetadata(value),\n              });\n            }\n\n            if (value.usage != null) {\n              usage = {\n                promptTokens: value.usage.prompt_tokens ?? undefined,\n                completionTokens: value.usage.completion_tokens ?? undefined,\n              };\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = mapOpenAICompatibleFinishReason(\n                choice.finish_reason,\n              );\n            }\n\n            if (choice?.delta == null) {\n              return;\n            }\n\n            const delta = choice.delta;\n\n            // enqueue reasoning before text deltas:\n            if (delta.reasoning_content != null) {\n              controller.enqueue({\n                type: 'reasoning',\n                textDelta: delta.reasoning_content,\n              });\n            }\n\n            if (delta.content != null) {\n              controller.enqueue({\n                type: 'text-delta',\n                textDelta: delta.content,\n              });\n            }\n\n            if (delta.tool_calls != null) {\n              for (const toolCallDelta of delta.tool_calls) {\n                const index = toolCallDelta.index;\n\n                if (toolCalls[index] == null) {\n                  if (toolCallDelta.type !== 'function') {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function' type.`,\n                    });\n                  }\n\n                  if (toolCallDelta.id == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'id' to be a string.`,\n                    });\n                  }\n\n                  if (toolCallDelta.function?.name == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function.name' to be a string.`,\n                    });\n                  }\n\n                  toolCalls[index] = {\n                    id: toolCallDelta.id,\n                    type: 'function',\n                    function: {\n                      name: toolCallDelta.function.name,\n                      arguments: toolCallDelta.function.arguments ?? '',\n                    },\n                    hasFinished: false,\n                  };\n\n                  const toolCall = toolCalls[index];\n\n                  if (\n                    toolCall.function?.name != null &&\n                    toolCall.function?.arguments != null\n                  ) {\n                    // send delta if the argument text has already started:\n                    if (toolCall.function.arguments.length > 0) {\n                      controller.enqueue({\n                        type: 'tool-call-delta',\n                        toolCallType: 'function',\n                        toolCallId: toolCall.id,\n                        toolName: toolCall.function.name,\n                        argsTextDelta: toolCall.function.arguments,\n                      });\n                    }\n\n                    // check if tool call is complete\n                    // (some providers send the full tool call in one chunk):\n                    if (isParsableJson(toolCall.function.arguments)) {\n                      controller.enqueue({\n                        type: 'tool-call',\n                        toolCallType: 'function',\n                        toolCallId: toolCall.id ?? generateId(),\n                        toolName: toolCall.function.name,\n                        args: toolCall.function.arguments,\n                      });\n                      toolCall.hasFinished = true;\n                    }\n                  }\n\n                  continue;\n                }\n\n                // existing tool call, merge if not finished\n                const toolCall = toolCalls[index];\n\n                if (toolCall.hasFinished) {\n                  continue;\n                }\n\n                if (toolCallDelta.function?.arguments != null) {\n                  toolCall.function!.arguments +=\n                    toolCallDelta.function?.arguments ?? '';\n                }\n\n                // send delta\n                controller.enqueue({\n                  type: 'tool-call-delta',\n                  toolCallType: 'function',\n                  toolCallId: toolCall.id,\n                  toolName: toolCall.function.name,\n                  argsTextDelta: toolCallDelta.function.arguments ?? '',\n                });\n\n                // check if tool call is complete\n                if (\n                  toolCall.function?.name != null &&\n                  toolCall.function?.arguments != null &&\n                  isParsableJson(toolCall.function.arguments)\n                ) {\n                  controller.enqueue({\n                    type: 'tool-call',\n                    toolCallType: 'function',\n                    toolCallId: toolCall.id ?? generateId(),\n                    toolName: toolCall.function.name,\n                    args: toolCall.function.arguments,\n                  });\n                  toolCall.hasFinished = true;\n                }\n              }\n            }\n          },\n\n          flush(controller) {\n            const metadata = metadataExtractor?.buildMetadata();\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage: {\n                promptTokens: usage.promptTokens ?? NaN,\n                completionTokens: usage.completionTokens ?? NaN,\n              },\n              ...(metadata && { providerMetadata: metadata }),\n            });\n          },\n        }),\n      ),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      warnings,\n      request: { body },\n    };\n  }\n}\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst OpenAICompatibleChatResponseSchema = z.object({\n  id: z.string().nullish(),\n  created: z.number().nullish(),\n  model: z.string().nullish(),\n  choices: z.array(\n    z.object({\n      message: z.object({\n        role: z.literal('assistant').nullish(),\n        content: z.string().nullish(),\n        reasoning_content: z.string().nullish(),\n        tool_calls: z\n          .array(\n            z.object({\n              id: z.string().nullish(),\n              type: z.literal('function'),\n              function: z.object({\n                name: z.string(),\n                arguments: z.string(),\n              }),\n            }),\n          )\n          .nullish(),\n      }),\n      finish_reason: z.string().nullish(),\n    }),\n  ),\n  usage: z\n    .object({\n      prompt_tokens: z.number().nullish(),\n      completion_tokens: z.number().nullish(),\n    })\n    .nullish(),\n});\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst createOpenAICompatibleChatChunkSchema = <ERROR_SCHEMA extends z.ZodType>(\n  errorSchema: ERROR_SCHEMA,\n) =>\n  z.union([\n    z.object({\n      id: z.string().nullish(),\n      created: z.number().nullish(),\n      model: z.string().nullish(),\n      choices: z.array(\n        z.object({\n          delta: z\n            .object({\n              role: z.enum(['assistant']).nullish(),\n              content: z.string().nullish(),\n              reasoning_content: z.string().nullish(),\n              tool_calls: z\n                .array(\n                  z.object({\n                    index: z.number(),\n                    id: z.string().nullish(),\n                    type: z.literal('function').optional(),\n                    function: z.object({\n                      name: z.string().nullish(),\n                      arguments: z.string().nullish(),\n                    }),\n                  }),\n                )\n                .nullish(),\n            })\n            .nullish(),\n          finish_reason: z.string().nullish(),\n        }),\n      ),\n      usage: z\n        .object({\n          prompt_tokens: z.number().nullish(),\n          completion_tokens: z.number().nullish(),\n        })\n        .nullish(),\n    }),\n    errorSchema,\n  ]);\n","import {\n  LanguageModelV1Prompt,\n  LanguageModelV1ProviderMetadata,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { convertUint8ArrayToBase64 } from '@ai-sdk/provider-utils';\nimport { OpenAICompatibleChatPrompt } from './openai-compatible-api-types';\n\nfunction getOpenAIMetadata(message: {\n  providerMetadata?: LanguageModelV1ProviderMetadata;\n}) {\n  return message?.providerMetadata?.openaiCompatible ?? {};\n}\n\nexport function convertToOpenAICompatibleChatMessages(\n  prompt: LanguageModelV1Prompt,\n): OpenAICompatibleChatPrompt {\n  const messages: OpenAICompatibleChatPrompt = [];\n  for (const { role, content, ...message } of prompt) {\n    const metadata = getOpenAIMetadata({ ...message });\n    switch (role) {\n      case 'system': {\n        messages.push({ role: 'system', content, ...metadata });\n        break;\n      }\n\n      case 'user': {\n        if (content.length === 1 && content[0].type === 'text') {\n          messages.push({\n            role: 'user',\n            content: content[0].text,\n            ...getOpenAIMetadata(content[0]),\n          });\n          break;\n        }\n\n        messages.push({\n          role: 'user',\n          content: content.map(part => {\n            const partMetadata = getOpenAIMetadata(part);\n            switch (part.type) {\n              case 'text': {\n                return { type: 'text', text: part.text, ...partMetadata };\n              }\n              case 'image': {\n                return {\n                  type: 'image_url',\n                  image_url: {\n                    url:\n                      part.image instanceof URL\n                        ? part.image.toString()\n                        : `data:${\n                            part.mimeType ?? 'image/jpeg'\n                          };base64,${convertUint8ArrayToBase64(part.image)}`,\n                  },\n                  ...partMetadata,\n                };\n              }\n              case 'file': {\n                throw new UnsupportedFunctionalityError({\n                  functionality: 'File content parts in user messages',\n                });\n              }\n            }\n          }),\n          ...metadata,\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        let text = '';\n        const toolCalls: Array<{\n          id: string;\n          type: 'function';\n          function: { name: string; arguments: string };\n        }> = [];\n\n        for (const part of content) {\n          const partMetadata = getOpenAIMetadata(part);\n          switch (part.type) {\n            case 'text': {\n              text += part.text;\n              break;\n            }\n            case 'tool-call': {\n              toolCalls.push({\n                id: part.toolCallId,\n                type: 'function',\n                function: {\n                  name: part.toolName,\n                  arguments: JSON.stringify(part.args),\n                },\n                ...partMetadata,\n              });\n              break;\n            }\n            default: {\n              const _exhaustiveCheck: never = part;\n              throw new Error(`Unsupported part: ${_exhaustiveCheck}`);\n            }\n          }\n        }\n\n        messages.push({\n          role: 'assistant',\n          content: text,\n          tool_calls: toolCalls.length > 0 ? toolCalls : undefined,\n          ...metadata,\n        });\n\n        break;\n      }\n\n      case 'tool': {\n        for (const toolResponse of content) {\n          const toolResponseMetadata = getOpenAIMetadata(toolResponse);\n          messages.push({\n            role: 'tool',\n            tool_call_id: toolResponse.toolCallId,\n            content: JSON.stringify(toolResponse.result),\n            ...toolResponseMetadata,\n          });\n        }\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  return messages;\n}\n","export function getResponseMetadata({\n  id,\n  model,\n  created,\n}: {\n  id?: string | undefined | null;\n  created?: number | undefined | null;\n  model?: string | undefined | null;\n}) {\n  return {\n    id: id ?? undefined,\n    modelId: model ?? undefined,\n    timestamp: created != null ? new Date(created * 1000) : undefined,\n  };\n}\n","import { LanguageModelV1FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAICompatibleFinishReason(\n  finishReason: string | null | undefined,\n): LanguageModelV1FinishReason {\n  switch (finishReason) {\n    case 'stop':\n      return 'stop';\n    case 'length':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    case 'function_call':\n    case 'tool_calls':\n      return 'tool-calls';\n    default:\n      return 'unknown';\n  }\n}\n","import { z, ZodSchema } from 'zod';\n\nexport const openaiCompatibleErrorDataSchema = z.object({\n  error: z.object({\n    message: z.string(),\n\n    // The additional information below is handled loosely to support\n    // OpenAI-compatible providers that have slightly different error\n    // responses:\n    type: z.string().nullish(),\n    param: z.any().nullish(),\n    code: z.union([z.string(), z.number()]).nullish(),\n  }),\n});\n\nexport type OpenAICompatibleErrorData = z.infer<\n  typeof openaiCompatibleErrorDataSchema\n>;\n\nexport type ProviderErrorStructure<T> = {\n  errorSchema: ZodSchema<T>;\n  errorToMessage: (error: T) => string;\n  isRetryable?: (response: Response, error?: T) => boolean;\n};\n\nexport const defaultOpenAICompatibleErrorStructure: ProviderErrorStructure<OpenAICompatibleErrorData> =\n  {\n    errorSchema: openaiCompatibleErrorDataSchema,\n    errorToMessage: data => data.error.message,\n  };\n","import {\n  LanguageModelV1,\n  LanguageModelV1CallWarning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\n\nexport function prepareTools({\n  mode,\n  structuredOutputs,\n}: {\n  mode: Parameters<LanguageModelV1['doGenerate']>[0]['mode'] & {\n    type: 'regular';\n  };\n  structuredOutputs: boolean;\n}): {\n  tools:\n    | undefined\n    | Array<{\n        type: 'function';\n        function: {\n          name: string;\n          description: string | undefined;\n          parameters: unknown;\n        };\n      }>;\n  tool_choice:\n    | { type: 'function'; function: { name: string } }\n    | 'auto'\n    | 'none'\n    | 'required'\n    | undefined;\n  toolWarnings: LanguageModelV1CallWarning[];\n} {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  const tools = mode.tools?.length ? mode.tools : undefined;\n  const toolWarnings: LanguageModelV1CallWarning[] = [];\n\n  if (tools == null) {\n    return { tools: undefined, tool_choice: undefined, toolWarnings };\n  }\n\n  const toolChoice = mode.toolChoice;\n\n  const openaiCompatTools: Array<{\n    type: 'function';\n    function: {\n      name: string;\n      description: string | undefined;\n      parameters: unknown;\n    };\n  }> = [];\n\n  for (const tool of tools) {\n    if (tool.type === 'provider-defined') {\n      toolWarnings.push({ type: 'unsupported-tool', tool });\n    } else {\n      openaiCompatTools.push({\n        type: 'function',\n        function: {\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.parameters,\n        },\n      });\n    }\n  }\n\n  if (toolChoice == null) {\n    return { tools: openaiCompatTools, tool_choice: undefined, toolWarnings };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n    case 'none':\n    case 'required':\n      return { tools: openaiCompatTools, tool_choice: type, toolWarnings };\n    case 'tool':\n      return {\n        tools: openaiCompatTools,\n        tool_choice: {\n          type: 'function',\n          function: {\n            name: toolChoice.toolName,\n          },\n        },\n        toolWarnings,\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new UnsupportedFunctionalityError({\n        functionality: `Unsupported tool choice type: ${_exhaustiveCheck}`,\n      });\n    }\n  }\n}\n","import {\n  APICallError,\n  LanguageModelV1,\n  LanguageModelV1CallWarning,\n  LanguageModelV1FinishReason,\n  LanguageModelV1StreamPart,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonErrorResponseHandler,\n  createJsonResponseHandler,\n  FetchFunction,\n  ParseResult,\n  postJsonToApi,\n  ResponseHandler,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\nimport { convertToOpenAICompatibleCompletionPrompt } from './convert-to-openai-compatible-completion-prompt';\nimport { getResponseMetadata } from './get-response-metadata';\nimport { mapOpenAICompatibleFinishReason } from './map-openai-compatible-finish-reason';\nimport {\n  OpenAICompatibleCompletionModelId,\n  OpenAICompatibleCompletionSettings,\n} from './openai-compatible-completion-settings';\nimport {\n  defaultOpenAICompatibleErrorStructure,\n  ProviderErrorStructure,\n} from './openai-compatible-error';\n\ntype OpenAICompatibleCompletionConfig = {\n  provider: string;\n  headers: () => Record<string, string | undefined>;\n  url: (options: { modelId: string; path: string }) => string;\n  fetch?: FetchFunction;\n  errorStructure?: ProviderErrorStructure<any>;\n};\n\nexport class OpenAICompatibleCompletionLanguageModel\n  implements LanguageModelV1\n{\n  readonly specificationVersion = 'v1';\n  readonly defaultObjectGenerationMode = undefined;\n\n  readonly modelId: OpenAICompatibleCompletionModelId;\n  readonly settings: OpenAICompatibleCompletionSettings;\n\n  private readonly config: OpenAICompatibleCompletionConfig;\n  private readonly failedResponseHandler: ResponseHandler<APICallError>;\n  private readonly chunkSchema; // type inferred via constructor\n\n  constructor(\n    modelId: OpenAICompatibleCompletionModelId,\n    settings: OpenAICompatibleCompletionSettings,\n    config: OpenAICompatibleCompletionConfig,\n  ) {\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n\n    // initialize error handling:\n    const errorStructure =\n      config.errorStructure ?? defaultOpenAICompatibleErrorStructure;\n    this.chunkSchema = createOpenAICompatibleCompletionChunkSchema(\n      errorStructure.errorSchema,\n    );\n    this.failedResponseHandler = createJsonErrorResponseHandler(errorStructure);\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private getArgs({\n    mode,\n    inputFormat,\n    prompt,\n    maxTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences: userStopSequences,\n    responseFormat,\n    seed,\n  }: Parameters<LanguageModelV1['doGenerate']>[0]) {\n    const type = mode.type;\n\n    const warnings: LanguageModelV1CallWarning[] = [];\n\n    if (topK != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'topK',\n      });\n    }\n\n    if (responseFormat != null && responseFormat.type !== 'text') {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'responseFormat',\n        details: 'JSON response format is not supported.',\n      });\n    }\n\n    const { prompt: completionPrompt, stopSequences } =\n      convertToOpenAICompatibleCompletionPrompt({ prompt, inputFormat });\n\n    const stop = [...(stopSequences ?? []), ...(userStopSequences ?? [])];\n\n    const baseArgs = {\n      // model id:\n      model: this.modelId,\n\n      // model specific settings:\n      echo: this.settings.echo,\n      logit_bias: this.settings.logitBias,\n      suffix: this.settings.suffix,\n      user: this.settings.user,\n\n      // standardized settings:\n      max_tokens: maxTokens,\n      temperature,\n      top_p: topP,\n      frequency_penalty: frequencyPenalty,\n      presence_penalty: presencePenalty,\n      seed,\n\n      // prompt:\n      prompt: completionPrompt,\n\n      // stop sequences:\n      stop: stop.length > 0 ? stop : undefined,\n    };\n\n    switch (type) {\n      case 'regular': {\n        if (mode.tools?.length) {\n          throw new UnsupportedFunctionalityError({\n            functionality: 'tools',\n          });\n        }\n\n        if (mode.toolChoice) {\n          throw new UnsupportedFunctionalityError({\n            functionality: 'toolChoice',\n          });\n        }\n\n        return { args: baseArgs, warnings };\n      }\n\n      case 'object-json': {\n        throw new UnsupportedFunctionalityError({\n          functionality: 'object-json mode',\n        });\n      }\n\n      case 'object-tool': {\n        throw new UnsupportedFunctionalityError({\n          functionality: 'object-tool mode',\n        });\n      }\n\n      default: {\n        const _exhaustiveCheck: never = type;\n        throw new Error(`Unsupported type: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV1['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV1['doGenerate']>>> {\n    const { args, warnings } = this.getArgs(options);\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: args,\n      failedResponseHandler: this.failedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiCompatibleCompletionResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const { prompt: rawPrompt, ...rawSettings } = args;\n    const choice = response.choices[0];\n\n    return {\n      text: choice.text,\n      usage: {\n        promptTokens: response.usage?.prompt_tokens ?? NaN,\n        completionTokens: response.usage?.completion_tokens ?? NaN,\n      },\n      finishReason: mapOpenAICompatibleFinishReason(choice.finish_reason),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      response: getResponseMetadata(response),\n      warnings,\n      request: { body: JSON.stringify(args) },\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV1['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV1['doStream']>>> {\n    const { args, warnings } = this.getArgs(options);\n\n    const body = {\n      ...args,\n      stream: true,\n    };\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: this.failedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        this.chunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const { prompt: rawPrompt, ...rawSettings } = args;\n\n    let finishReason: LanguageModelV1FinishReason = 'unknown';\n    let usage: { promptTokens: number; completionTokens: number } = {\n      promptTokens: Number.NaN,\n      completionTokens: Number.NaN,\n    };\n    let isFirstChunk = true;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<z.infer<typeof this.chunkSchema>>,\n          LanguageModelV1StreamPart\n        >({\n          transform(chunk, controller) {\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            // handle error chunks:\n            if ('error' in value) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: value.error });\n              return;\n            }\n\n            if (isFirstChunk) {\n              isFirstChunk = false;\n\n              controller.enqueue({\n                type: 'response-metadata',\n                ...getResponseMetadata(value),\n              });\n            }\n\n            if (value.usage != null) {\n              usage = {\n                promptTokens: value.usage.prompt_tokens,\n                completionTokens: value.usage.completion_tokens,\n              };\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = mapOpenAICompatibleFinishReason(\n                choice.finish_reason,\n              );\n            }\n\n            if (choice?.text != null) {\n              controller.enqueue({\n                type: 'text-delta',\n                textDelta: choice.text,\n              });\n            }\n          },\n\n          flush(controller) {\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage,\n            });\n          },\n        }),\n      ),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      warnings,\n      request: { body: JSON.stringify(body) },\n    };\n  }\n}\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiCompatibleCompletionResponseSchema = z.object({\n  id: z.string().nullish(),\n  created: z.number().nullish(),\n  model: z.string().nullish(),\n  choices: z.array(\n    z.object({\n      text: z.string(),\n      finish_reason: z.string(),\n    }),\n  ),\n  usage: z\n    .object({\n      prompt_tokens: z.number(),\n      completion_tokens: z.number(),\n    })\n    .nullish(),\n});\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst createOpenAICompatibleCompletionChunkSchema = <\n  ERROR_SCHEMA extends z.ZodType,\n>(\n  errorSchema: ERROR_SCHEMA,\n) =>\n  z.union([\n    z.object({\n      id: z.string().nullish(),\n      created: z.number().nullish(),\n      model: z.string().nullish(),\n      choices: z.array(\n        z.object({\n          text: z.string(),\n          finish_reason: z.string().nullish(),\n          index: z.number(),\n        }),\n      ),\n      usage: z\n        .object({\n          prompt_tokens: z.number(),\n          completion_tokens: z.number(),\n        })\n        .nullish(),\n    }),\n    errorSchema,\n  ]);\n","import {\n  InvalidPromptError,\n  LanguageModelV1Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\n\nexport function convertToOpenAICompatibleCompletionPrompt({\n  prompt,\n  inputFormat,\n  user = 'user',\n  assistant = 'assistant',\n}: {\n  prompt: LanguageModelV1Prompt;\n  inputFormat: 'prompt' | 'messages';\n  user?: string;\n  assistant?: string;\n}): {\n  prompt: string;\n  stopSequences?: string[];\n} {\n  // When the user supplied a prompt input, we don't transform it:\n  if (\n    inputFormat === 'prompt' &&\n    prompt.length === 1 &&\n    prompt[0].role === 'user' &&\n    prompt[0].content.length === 1 &&\n    prompt[0].content[0].type === 'text'\n  ) {\n    return { prompt: prompt[0].content[0].text };\n  }\n\n  // otherwise transform to a chat message format:\n  let text = '';\n\n  // if first message is a system message, add it to the text:\n  if (prompt[0].role === 'system') {\n    text += `${prompt[0].content}\\n\\n`;\n    prompt = prompt.slice(1);\n  }\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        throw new InvalidPromptError({\n          message: 'Unexpected system message in prompt: ${content}',\n          prompt,\n        });\n      }\n\n      case 'user': {\n        const userMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n              case 'image': {\n                throw new UnsupportedFunctionalityError({\n                  functionality: 'images',\n                });\n              }\n            }\n          })\n          .join('');\n\n        text += `${user}:\\n${userMessage}\\n\\n`;\n        break;\n      }\n\n      case 'assistant': {\n        const assistantMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n              case 'tool-call': {\n                throw new UnsupportedFunctionalityError({\n                  functionality: 'tool-call messages',\n                });\n              }\n            }\n          })\n          .join('');\n\n        text += `${assistant}:\\n${assistantMessage}\\n\\n`;\n        break;\n      }\n\n      case 'tool': {\n        throw new UnsupportedFunctionalityError({\n          functionality: 'tool messages',\n        });\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  // Assistant message prefix:\n  text += `${assistant}:\\n`;\n\n  return {\n    prompt: text,\n    stopSequences: [`\\n${user}:`],\n  };\n}\n","import {\n  EmbeddingModelV1,\n  TooManyEmbeddingValuesForCallError,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonErrorResponseHandler,\n  createJsonResponseHandler,\n  FetchFunction,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\nimport {\n  OpenAICompatibleEmbeddingModelId,\n  OpenAICompatibleEmbeddingSettings,\n} from './openai-compatible-embedding-settings';\nimport {\n  defaultOpenAICompatibleErrorStructure,\n  ProviderErrorStructure,\n} from './openai-compatible-error';\n\ntype OpenAICompatibleEmbeddingConfig = {\n  /**\nOverride the maximum number of embeddings per call.\n   */\n  maxEmbeddingsPerCall?: number;\n\n  /**\nOverride the parallelism of embedding calls.\n  */\n  supportsParallelCalls?: boolean;\n\n  provider: string;\n  url: (options: { modelId: string; path: string }) => string;\n  headers: () => Record<string, string | undefined>;\n  fetch?: FetchFunction;\n  errorStructure?: ProviderErrorStructure<any>;\n};\n\nexport class OpenAICompatibleEmbeddingModel\n  implements EmbeddingModelV1<string>\n{\n  readonly specificationVersion = 'v1';\n  readonly modelId: OpenAICompatibleEmbeddingModelId;\n\n  private readonly config: OpenAICompatibleEmbeddingConfig;\n  private readonly settings: OpenAICompatibleEmbeddingSettings;\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  get maxEmbeddingsPerCall(): number {\n    return this.config.maxEmbeddingsPerCall ?? 2048;\n  }\n\n  get supportsParallelCalls(): boolean {\n    return this.config.supportsParallelCalls ?? true;\n  }\n\n  constructor(\n    modelId: OpenAICompatibleEmbeddingModelId,\n    settings: OpenAICompatibleEmbeddingSettings,\n    config: OpenAICompatibleEmbeddingConfig,\n  ) {\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n  }\n\n  async doEmbed({\n    values,\n    headers,\n    abortSignal,\n  }: Parameters<EmbeddingModelV1<string>['doEmbed']>[0]): Promise<\n    Awaited<ReturnType<EmbeddingModelV1<string>['doEmbed']>>\n  > {\n    if (values.length > this.maxEmbeddingsPerCall) {\n      throw new TooManyEmbeddingValuesForCallError({\n        provider: this.provider,\n        modelId: this.modelId,\n        maxEmbeddingsPerCall: this.maxEmbeddingsPerCall,\n        values,\n      });\n    }\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/embeddings',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        input: values,\n        encoding_format: 'float',\n        dimensions: this.settings.dimensions,\n        user: this.settings.user,\n      },\n      failedResponseHandler: createJsonErrorResponseHandler(\n        this.config.errorStructure ?? defaultOpenAICompatibleErrorStructure,\n      ),\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiTextEmbeddingResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      embeddings: response.data.map(item => item.embedding),\n      usage: response.usage\n        ? { tokens: response.usage.prompt_tokens }\n        : undefined,\n      rawResponse: { headers: responseHeaders },\n    };\n  }\n}\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiTextEmbeddingResponseSchema = z.object({\n  data: z.array(z.object({ embedding: z.array(z.number()) })),\n  usage: z.object({ prompt_tokens: z.number() }).nullish(),\n});\n","import {\n  EmbeddingModelV1,\n  LanguageModelV1,\n  ProviderV1,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  loadApiKey,\n  withoutTrailingSlash,\n} from '@ai-sdk/provider-utils';\nimport { OpenAICompatibleChatLanguageModel } from './openai-compatible-chat-language-model';\nimport { OpenAICompatibleChatSettings } from './openai-compatible-chat-settings';\nimport { OpenAICompatibleCompletionLanguageModel } from './openai-compatible-completion-language-model';\nimport { OpenAICompatibleCompletionSettings } from './openai-compatible-completion-settings';\nimport { OpenAICompatibleEmbeddingSettings } from './openai-compatible-embedding-settings';\nimport { OpenAICompatibleEmbeddingModel } from './openai-compatible-embedding-model';\n\nexport interface OpenAICompatibleProvider<\n  CHAT_MODEL_IDS extends string = string,\n  COMPLETION_MODEL_IDS extends string = string,\n  EMBEDDING_MODEL_IDS extends string = string,\n> extends ProviderV1 {\n  (\n    modelId: CHAT_MODEL_IDS,\n    settings?: OpenAICompatibleChatSettings,\n  ): LanguageModelV1;\n\n  languageModel(\n    modelId: CHAT_MODEL_IDS,\n    settings?: OpenAICompatibleChatSettings,\n  ): LanguageModelV1;\n\n  chatModel(\n    modelId: CHAT_MODEL_IDS,\n    settings?: OpenAICompatibleChatSettings,\n  ): LanguageModelV1;\n\n  completionModel(\n    modelId: COMPLETION_MODEL_IDS,\n    settings?: OpenAICompatibleCompletionSettings,\n  ): LanguageModelV1;\n\n  textEmbeddingModel(\n    modelId: EMBEDDING_MODEL_IDS,\n    settings?: OpenAICompatibleEmbeddingSettings,\n  ): EmbeddingModelV1<string>;\n}\n\nexport interface OpenAICompatibleProviderSettings {\n  /**\nBase URL for the API calls.\n   */\n  baseURL?: string;\n\n  /**\nAPI key for authenticating requests. If specified, adds an `Authorization`\nheader to request headers with the value `Bearer <apiKey>`. This will be added\nbefore any headers potentially specified in the `headers` option.\n   */\n  apiKey?: string;\n\n  /**\nOptional custom headers to include in requests. These will be added to request headers\nafter any headers potentially added by use of the `apiKey` option.\n   */\n  headers?: Record<string, string>;\n\n  /**\nOptional custom url query parameters to include in request urls.\n   */\n  queryParams?: Record<string, string>;\n\n  /**\nCustom fetch implementation. You can use it as a middleware to intercept requests,\nor to provide a custom fetch implementation for e.g. testing.\n   */\n  fetch?: FetchFunction;\n\n  /**\nProvider name.\n   */\n  name?: string;\n}\n\n/**\nCreate an OpenAICompatible provider instance.\n */\nexport function createOpenAICompatible<\n  CHAT_MODEL_IDS extends string,\n  COMPLETION_MODEL_IDS extends string,\n  EMBEDDING_MODEL_IDS extends string,\n>(\n  options: OpenAICompatibleProviderSettings,\n): OpenAICompatibleProvider<\n  CHAT_MODEL_IDS,\n  COMPLETION_MODEL_IDS,\n  EMBEDDING_MODEL_IDS\n> {\n  if (!options.baseURL) {\n    throw new Error('Base URL is required');\n  }\n  const baseURL = withoutTrailingSlash(options.baseURL);\n\n  if (!options.name) {\n    throw new Error('Provider name is required');\n  }\n  const providerName = options.name;\n\n  interface CommonModelConfig {\n    provider: string;\n    url: ({ path }: { path: string }) => string;\n    headers: () => Record<string, string>;\n    fetch?: FetchFunction;\n  }\n\n  const getHeaders = () => ({\n    ...(options.apiKey && { Authorization: `Bearer ${options.apiKey}` }),\n    ...options.headers,\n  });\n\n  const getCommonModelConfig = (modelType: string): CommonModelConfig => ({\n    provider: `${providerName}.${modelType}`,\n    url: ({ path }) => {\n      const url = new URL(`${baseURL}${path}`);\n      if (options.queryParams) {\n        url.search = new URLSearchParams(options.queryParams).toString();\n      }\n      return url.toString();\n    },\n    headers: getHeaders,\n    fetch: options.fetch,\n  });\n\n  const createLanguageModel = (\n    modelId: CHAT_MODEL_IDS,\n    settings: OpenAICompatibleChatSettings = {},\n  ) => createChatModel(modelId, settings);\n\n  const createChatModel = (\n    modelId: CHAT_MODEL_IDS,\n    settings: OpenAICompatibleChatSettings = {},\n  ) =>\n    new OpenAICompatibleChatLanguageModel(modelId, settings, {\n      ...getCommonModelConfig('chat'),\n      defaultObjectGenerationMode: 'tool',\n    });\n\n  const createCompletionModel = (\n    modelId: COMPLETION_MODEL_IDS,\n    settings: OpenAICompatibleCompletionSettings = {},\n  ) =>\n    new OpenAICompatibleCompletionLanguageModel(\n      modelId,\n      settings,\n      getCommonModelConfig('completion'),\n    );\n\n  const createEmbeddingModel = (\n    modelId: EMBEDDING_MODEL_IDS,\n    settings: OpenAICompatibleEmbeddingSettings = {},\n  ) =>\n    new OpenAICompatibleEmbeddingModel(\n      modelId,\n      settings,\n      getCommonModelConfig('embedding'),\n    );\n\n  const provider = (\n    modelId: CHAT_MODEL_IDS,\n    settings?: OpenAICompatibleChatSettings,\n  ) => createLanguageModel(modelId, settings);\n\n  provider.languageModel = createLanguageModel;\n  provider.chatModel = createChatModel;\n  provider.completionModel = createCompletionModel;\n  provider.textEmbeddingModel = createEmbeddingModel;\n\n  return provider as OpenAICompatibleProvider<\n    CHAT_MODEL_IDS,\n    COMPLETION_MODEL_IDS,\n    EMBEDDING_MODEL_IDS\n  >;\n}\n"],"names":["z","UnsupportedFunctionalityError","_a","toolCall","z","UnsupportedFunctionalityError","combineHeaders","createEventSourceResponseHandler","createJsonErrorResponseHandler","createJsonResponseHandler","postJsonToApi","z","UnsupportedFunctionalityError","createJsonErrorResponseHandler","UnsupportedFunctionalityError","postJsonToApi","combineHeaders","createJsonResponseHandler","createEventSourceResponseHandler","z","combineHeaders","createJsonErrorResponseHandler","createJsonResponseHandler","postJsonToApi","z","postJsonToApi","combineHeaders","createJsonErrorResponseHandler","createJsonResponseHandler","z"],"mappings":";;;;;;;AAAA;AASA;AAYA,SAAS,KAAAA,UAAS;;;;;;ACblB,SAAS,kBAAkB,OAAA,EAExB;IAVH,IAAA,IAAA;IAWE,OAAA,CAAO,KAAA,CAAA,KAAA,WAAA,OAAA,KAAA,IAAA,QAAS,gBAAA,KAAT,OAAA,KAAA,IAAA,GAA2B,gBAAA,KAA3B,OAAA,KAA+C,CAAC;AACzD;AAEO,SAAS,sCACd,MAAA,EAC4B;IAC5B,MAAM,WAAuC,CAAC,CAAA;IAC9C,KAAA,MAAW,EAAE,IAAA,EAAM,OAAA,EAAS,GAAG,QAAQ,CAAA,IAAK,OAAQ;QAClD,MAAM,WAAW,kBAAkB;YAAE,GAAG,OAAA;QAAQ,CAAC;QACjD,OAAQ,MAAM;YACZ,KAAK;gBAAU;oBACb,SAAS,IAAA,CAAK;wBAAE,MAAM;wBAAU;wBAAS,GAAG,QAAA;oBAAS,CAAC;oBACtD;gBACF;YAEA,KAAK;gBAAQ;oBACX,IAAI,QAAQ,MAAA,KAAW,KAAK,OAAA,CAAQ,CAAC,CAAA,CAAE,IAAA,KAAS,QAAQ;wBACtD,SAAS,IAAA,CAAK;4BACZ,MAAM;4BACN,SAAS,OAAA,CAAQ,CAAC,CAAA,CAAE,IAAA;4BACpB,GAAG,kBAAkB,OAAA,CAAQ,CAAC,CAAC,CAAA;wBACjC,CAAC;wBACD;oBACF;oBAEA,SAAS,IAAA,CAAK;wBACZ,MAAM;wBACN,SAAS,QAAQ,GAAA,CAAI,CAAA,SAAQ;4BAtCvC,IAAA;4BAuCY,MAAM,eAAe,kBAAkB,IAAI;4BAC3C,OAAQ,KAAK,IAAA,EAAM;gCACjB,KAAK;oCAAQ;wCACX,OAAO;4CAAE,MAAM;4CAAQ,MAAM,KAAK,IAAA;4CAAM,GAAG,YAAA;wCAAa;oCAC1D;gCACA,KAAK;oCAAS;wCACZ,OAAO;4CACL,MAAM;4CACN,WAAW;gDACT,KACE,KAAK,KAAA,YAAiB,MAClB,KAAK,KAAA,CAAM,QAAA,CAAS,IACpB,CAAA,KAAA,EAAA,CACE,KAAA,KAAK,QAAA,KAAL,OAAA,KAAiB,YACnB,CAAA,QAAA,4KAAW,4BAAA,EAA0B,KAAK,KAAK,CAAC,EAAA;4CACxD;4CACA,GAAG,YAAA;wCACL;oCACF;gCACA,KAAK;oCAAQ;wCACX,MAAM,iKAAI,gCAAA,CAA8B;4CACtC,eAAe;wCACjB,CAAC;oCACH;4BACF;wBACF,CAAC;wBACD,GAAG,QAAA;oBACL,CAAC;oBAED;gBACF;YAEA,KAAK;gBAAa;oBAChB,IAAI,OAAO;oBACX,MAAM,YAID,CAAC,CAAA;oBAEN,KAAA,MAAW,QAAQ,QAAS;wBAC1B,MAAM,eAAe,kBAAkB,IAAI;wBAC3C,OAAQ,KAAK,IAAA,EAAM;4BACjB,KAAK;gCAAQ;oCACX,QAAQ,KAAK,IAAA;oCACb;gCACF;4BACA,KAAK;gCAAa;oCAChB,UAAU,IAAA,CAAK;wCACb,IAAI,KAAK,UAAA;wCACT,MAAM;wCACN,UAAU;4CACR,MAAM,KAAK,QAAA;4CACX,WAAW,KAAK,SAAA,CAAU,KAAK,IAAI;wCACrC;wCACA,GAAG,YAAA;oCACL,CAAC;oCACD;gCACF;4BACA;gCAAS;oCACP,MAAM,mBAA0B;oCAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;gCACzD;wBACF;oBACF;oBAEA,SAAS,IAAA,CAAK;wBACZ,MAAM;wBACN,SAAS;wBACT,YAAY,UAAU,MAAA,GAAS,IAAI,YAAY,KAAA;wBAC/C,GAAG,QAAA;oBACL,CAAC;oBAED;gBACF;YAEA,KAAK;gBAAQ;oBACX,KAAA,MAAW,gBAAgB,QAAS;wBAClC,MAAM,uBAAuB,kBAAkB,YAAY;wBAC3D,SAAS,IAAA,CAAK;4BACZ,MAAM;4BACN,cAAc,aAAa,UAAA;4BAC3B,SAAS,KAAK,SAAA,CAAU,aAAa,MAAM;4BAC3C,GAAG,oBAAA;wBACL,CAAC;oBACH;oBACA;gBACF;YAEA;gBAAS;oBACP,MAAM,mBAA0B;oBAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;gBACzD;QACF;IACF;IAEA,OAAO;AACT;;ACxIO,SAAS,oBAAoB,EAClC,EAAA,EACA,KAAA,EACA,OAAA,EACF,EAIG;IACD,OAAO;QACL,IAAI,MAAA,OAAA,KAAM,KAAA;QACV,SAAS,SAAA,OAAA,QAAS,KAAA;QAClB,WAAW,WAAW,OAAO,IAAI,KAAK,UAAU,GAAI,IAAI,KAAA;IAC1D;AACF;;ACZO,SAAS,gCACd,YAAA,EAC6B;IAC7B,OAAQ,cAAc;QACpB,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;QACL,KAAK;YACH,OAAO;QACT;YACE,OAAO;IACX;AACF;;AChBO,IAAM,0KAAkC,IAAA,CAAE,MAAA,CAAO;IACtD,+IAAO,IAAA,CAAE,MAAA,CAAO;QACd,iJAAS,IAAA,CAAE,MAAA,CAAO;QAAA,iEAAA;QAAA,iEAAA;QAAA,aAAA;QAKlB,MAAM,4IAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QACzB,+IAAO,IAAA,CAAE,GAAA,CAAI,EAAE,OAAA,CAAQ;QACvB,MAAM,4IAAA,CAAE,KAAA,CAAM;oJAAC,IAAA,CAAE,MAAA,CAAO;mJAAG,KAAA,CAAE,MAAA,CAAO,CAAC;SAAC,EAAE,OAAA,CAAQ;IAClD,CAAC;AACH,CAAC;AAYM,IAAM,wCACX;IACE,aAAa;IACb,gBAAgB,CAAA,OAAQ,KAAK,KAAA,CAAM,OAAA;AACrC;;ACvBK,SAAS,aAAa,EAC3B,IAAA,EACA,iBAAA,EACF,EAuBE;IAhCF,IAAA;IAkCE,MAAM,QAAA,CAAA,CAAQ,KAAA,KAAK,KAAA,KAAL,OAAA,KAAA,IAAA,GAAY,MAAA,IAAS,KAAK,KAAA,GAAQ,KAAA;IAChD,MAAM,eAA6C,CAAC,CAAA;IAEpD,IAAI,SAAS,MAAM;QACjB,OAAO;YAAE,OAAO,KAAA;YAAW,aAAa,KAAA;YAAW;QAAa;IAClE;IAEA,MAAM,aAAa,KAAK,UAAA;IAExB,MAAM,oBAOD,CAAC,CAAA;IAEN,KAAA,MAAW,QAAQ,MAAO;QACxB,IAAI,KAAK,IAAA,KAAS,oBAAoB;YACpC,aAAa,IAAA,CAAK;gBAAE,MAAM;gBAAoB;YAAK,CAAC;QACtD,OAAO;YACL,kBAAkB,IAAA,CAAK;gBACrB,MAAM;gBACN,UAAU;oBACR,MAAM,KAAK,IAAA;oBACX,aAAa,KAAK,WAAA;oBAClB,YAAY,KAAK,UAAA;gBACnB;YACF,CAAC;QACH;IACF;IAEA,IAAI,cAAc,MAAM;QACtB,OAAO;YAAE,OAAO;YAAmB,aAAa,KAAA;YAAW;QAAa;IAC1E;IAEA,MAAM,OAAO,WAAW,IAAA;IAExB,OAAQ,MAAM;QACZ,KAAK;QACL,KAAK;QACL,KAAK;YACH,OAAO;gBAAE,OAAO;gBAAmB,aAAa;gBAAM;YAAa;QACrE,KAAK;YACH,OAAO;gBACL,OAAO;gBACP,aAAa;oBACX,MAAM;oBACN,UAAU;wBACR,MAAM,WAAW,QAAA;oBACnB;gBACF;gBACA;YACF;QACF;YAAS;gBACP,MAAM,mBAA0B;gBAChC,MAAM,iKAAIC,gCAAAA,CAA8B;oBACtC,eAAe,CAAA,8BAAA,EAAiC,gBAAgB,EAAA;gBAClE,CAAC;YACH;IACF;AACF;;ALvCO,IAAM,oCAAN,MAAmE;IAAA,gCAAA;IAYxE,YACE,OAAA,EACA,QAAA,EACA,MAAA,CACA;QAfF,IAAA,CAAS,oBAAA,GAAuB;QA1DlC,IAAA,IAAA;QA0EI,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,MAAA,GAAS;QAGd,MAAM,iBAAA,CACJ,KAAA,OAAO,cAAA,KAAP,OAAA,KAAyB;QAC3B,IAAA,CAAK,WAAA,GAAc,sCACjB,eAAe,WAAA;QAEjB,IAAA,CAAK,qBAAA,6KAAwB,iCAAA,EAA+B,cAAc;QAE1E,IAAA,CAAK,yBAAA,GAAA,CAA4B,KAAA,OAAO,yBAAA,KAAP,OAAA,KAAoC;IACvE;IAEA,IAAI,8BAA2D;QAC7D,OAAO,IAAA,CAAK,MAAA,CAAO,2BAAA;IACrB;IAEA,IAAI,WAAmB;QACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA;IACrB;IAEQ,QAAQ,EACd,IAAA,EACA,MAAA,EACA,SAAA,EACA,WAAA,EACA,IAAA,EACA,IAAA,EACA,gBAAA,EACA,eAAA,EACA,aAAA,EACA,cAAA,EACA,IAAA,EACF,EAAiD;QA7GnD,IAAA,IAAA;QA8GI,MAAM,OAAO,KAAK,IAAA;QAElB,MAAM,WAAyC,CAAC,CAAA;QAEhD,IAAI,QAAQ,MAAM;YAChB,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;YACX,CAAC;QACH;QAEA,IAAA,CACE,kBAAA,OAAA,KAAA,IAAA,eAAgB,IAAA,MAAS,UACzB,eAAe,MAAA,IAAU,QACzB,CAAC,IAAA,CAAK,yBAAA,EACN;YACA,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;gBACT,SACE;YACJ,CAAC;QACH;QAEA,MAAM,WAAW;YAAA,YAAA;YAEf,OAAO,IAAA,CAAK,OAAA;YAAA,2BAAA;YAGZ,MAAM,IAAA,CAAK,QAAA,CAAS,IAAA;YAAA,yBAAA;YAGpB,YAAY;YACZ;YACA,OAAO;YACP,mBAAmB;YACnB,kBAAkB;YAClB,iBAAA,CACE,kBAAA,OAAA,KAAA,IAAA,eAAgB,IAAA,MAAS,SACrB,IAAA,CAAK,yBAAA,KAA8B,QACnC,eAAe,MAAA,IAAU,OACvB;gBACE,MAAM;gBACN,aAAa;oBACX,QAAQ,eAAe,MAAA;oBACvB,MAAA,CAAM,KAAA,eAAe,IAAA,KAAf,OAAA,KAAuB;oBAC7B,aAAa,eAAe,WAAA;gBAC9B;YACF,IACA;gBAAE,MAAM;YAAc,IACxB,KAAA;YAEN,MAAM;YACN;YAAA,YAAA;YAGA,UAAU,sCAAsC,MAAM;QACxD;QAEA,OAAQ,MAAM;YACZ,KAAK;gBAAW;oBACd,MAAM,EAAE,KAAA,EAAO,WAAA,EAAa,YAAA,CAAa,CAAA,GAAI,aAAa;wBACxD;wBACA,mBAAmB,IAAA,CAAK,yBAAA;oBAC1B,CAAC;oBAED,OAAO;wBACL,MAAM;4BAAE,GAAG,QAAA;4BAAU;4BAAO;wBAAY;wBACxC,UAAU,CAAC;+BAAG,UAAU;+BAAG,YAAY;yBAAA;oBACzC;gBACF;YAEA,KAAK;gBAAe;oBAClB,OAAO;wBACL,MAAM;4BACJ,GAAG,QAAA;4BACH,iBACE,IAAA,CAAK,yBAAA,KAA8B,QAAQ,KAAK,MAAA,IAAU,OACtD;gCACE,MAAM;gCACN,aAAa;oCACX,QAAQ,KAAK,MAAA;oCACb,MAAA,CAAM,KAAA,KAAK,IAAA,KAAL,OAAA,KAAa;oCACnB,aAAa,KAAK,WAAA;gCACpB;4BACF,IACA;gCAAE,MAAM;4BAAc;wBAC9B;wBACA;oBACF;gBACF;YAEA,KAAK;gBAAe;oBAClB,OAAO;wBACL,MAAM;4BACJ,GAAG,QAAA;4BACH,aAAa;gCACX,MAAM;gCACN,UAAU;oCAAE,MAAM,KAAK,IAAA,CAAK,IAAA;gCAAK;4BACnC;4BACA,OAAO;gCACL;oCACE,MAAM;oCACN,UAAU;wCACR,MAAM,KAAK,IAAA,CAAK,IAAA;wCAChB,aAAa,KAAK,IAAA,CAAK,WAAA;wCACvB,YAAY,KAAK,IAAA,CAAK,UAAA;oCACxB;gCACF;6BACF;wBACF;wBACA;oBACF;gBACF;YAEA;gBAAS;oBACP,MAAM,mBAA0B;oBAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;gBACzD;QACF;IACF;IAEA,MAAM,WACJ,OAAA,EAC6D;QA1OjE,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;QA2OI,MAAM,EAAE,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,IAAA,CAAK,OAAA,CAAQ;YAAE,GAAG,OAAA;QAAQ,CAAC;QAEtD,MAAM,OAAO,KAAK,SAAA,CAAU,IAAI;QAEhC,MAAM,EACJ,eAAA,EACA,OAAO,YAAA,EACP,UAAU,UAAA,EACZ,GAAI,UAAM,sLAAA,EAAc;YACtB,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,mLAAS,iBAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D,MAAM;YACN,uBAAuB,IAAA,CAAK,qBAAA;YAC5B,4BAA2B,qMAAA,EACzB;YAEF,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,MAAM,EAAE,UAAU,SAAA,EAAW,GAAG,YAAY,CAAA,GAAI;QAChD,MAAM,SAAS,aAAa,OAAA,CAAQ,CAAC,CAAA;QACrC,MAAM,mBAAA,CAAmB,KAAA,CAAA,KAAA,IAAA,CAAK,MAAA,CAAO,iBAAA,KAAZ,OAAA,KAAA,IAAA,GAA+B,eAAA,KAA/B,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,IAAiD;YACxE;QACF;QAEA,OAAO;YACL,MAAA,CAAM,KAAA,OAAO,OAAA,CAAQ,OAAA,KAAf,OAAA,KAA0B,KAAA;YAChC,WAAA,CAAW,KAAA,OAAO,OAAA,CAAQ,iBAAA,KAAf,OAAA,KAAoC,KAAA;YAC/C,WAAA,CAAW,KAAA,OAAO,OAAA,CAAQ,UAAA,KAAf,OAAA,KAAA,IAAA,GAA2B,GAAA,CAAI,CAAA,aAAS;gBA3QzD,IAAAC;gBA2Q6D,OAAA;oBACrD,cAAc;oBACd,YAAA,CAAYA,MAAA,SAAS,EAAA,KAAT,OAAAA,gLAAe,aAAA,CAAW;oBACtC,UAAU,SAAS,QAAA,CAAS,IAAA;oBAC5B,MAAM,SAAS,QAAA,CAAS,SAAA;gBAC1B;YAAA;YACA,cAAc,gCAAgC,OAAO,aAAa;YAClE,OAAO;gBACL,cAAA,CAAc,KAAA,CAAA,KAAA,aAAa,KAAA,KAAb,OAAA,KAAA,IAAA,GAAoB,aAAA,KAApB,OAAA,KAAqC;gBACnD,kBAAA,CAAkB,KAAA,CAAA,KAAA,aAAa,KAAA,KAAb,OAAA,KAAA,IAAA,GAAoB,iBAAA,KAApB,OAAA,KAAyC;YAC7D;YACA,GAAI,oBAAoB;gBAAE;YAAiB,CAAA;YAC3C,SAAS;gBAAE;gBAAW;YAAY;YAClC,aAAa;gBAAE,SAAS;YAAgB;YACxC,UAAU,oBAAoB,YAAY;YAC1C;YACA,SAAS;gBAAE;YAAK;QAClB;IACF;IAEA,MAAM,SACJ,OAAA,EAC2D;QAjS/D,IAAA;QAkSI,IAAI,IAAA,CAAK,QAAA,CAAS,iBAAA,EAAmB;YACnC,MAAM,SAAS,MAAM,IAAA,CAAK,UAAA,CAAW,OAAO;YAC5C,MAAM,kBAAkB,IAAI,eAA0C;gBACpE,OAAM,UAAA,EAAY;oBAChB,WAAW,OAAA,CAAQ;wBAAE,MAAM;wBAAqB,GAAG,OAAO,QAAA;oBAAS,CAAC;oBACpE,IAAI,OAAO,SAAA,EAAW;wBACpB,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,WAAW,OAAO,SAAA;wBACpB,CAAC;oBACH;oBACA,IAAI,OAAO,IAAA,EAAM;wBACf,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,WAAW,OAAO,IAAA;wBACpB,CAAC;oBACH;oBACA,IAAI,OAAO,SAAA,EAAW;wBACpB,KAAA,MAAW,YAAY,OAAO,SAAA,CAAW;4BACvC,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,GAAG,QAAA;4BACL,CAAC;wBACH;oBACF;oBACA,WAAW,OAAA,CAAQ;wBACjB,MAAM;wBACN,cAAc,OAAO,YAAA;wBACrB,OAAO,OAAO,KAAA;wBACd,UAAU,OAAO,QAAA;wBACjB,kBAAkB,OAAO,gBAAA;oBAC3B,CAAC;oBACD,WAAW,KAAA,CAAM;gBACnB;YACF,CAAC;YACD,OAAO;gBACL,QAAQ;gBACR,SAAS,OAAO,OAAA;gBAChB,aAAa,OAAO,WAAA;gBACpB,UAAU,OAAO,QAAA;YACnB;QACF;QAEA,MAAM,EAAE,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,IAAA,CAAK,OAAA,CAAQ;YAAE,GAAG,OAAA;QAAQ,CAAC;QAEtD,MAAM,OAAO,KAAK,SAAA,CAAU;YAAE,GAAG,IAAA;YAAM,QAAQ;QAAK,CAAC;QACrD,MAAM,oBAAA,CACJ,KAAA,IAAA,CAAK,MAAA,CAAO,iBAAA,KAAZ,OAAA,KAAA,IAAA,GAA+B,qBAAA;QAEjC,MAAM,EAAE,eAAA,EAAiB,OAAO,QAAA,CAAS,CAAA,GAAI,MAAM,0LAAA,EAAc;YAC/D,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,mLAAS,iBAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D,MAAM;gBACJ,GAAG,IAAA;gBACH,QAAQ;YACV;YACA,uBAAuB,IAAA,CAAK,qBAAA;YAC5B,qMAA2B,mCAAA,EACzB,IAAA,CAAK,WAAA;YAEP,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,MAAM,EAAE,UAAU,SAAA,EAAW,GAAG,YAAY,CAAA,GAAI;QAEhD,MAAM,YAQD,CAAC,CAAA;QAEN,IAAI,eAA4C;QAChD,IAAI,QAGA;YACF,cAAc,KAAA;YACd,kBAAkB,KAAA;QACpB;QACA,IAAI,eAAe;QAEnB,OAAO;YACL,QAAQ,SAAS,WAAA,CACf,IAAI,gBAGF;gBAAA,mFAAA;gBAEA,WAAU,KAAA,EAAO,UAAA,EAAY;oBAlYvC,IAAAA,KAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;oBAoYY,IAAI,CAAC,MAAM,OAAA,EAAS;wBAClB,eAAe;wBACf,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO,MAAM,KAAA;wBAAM,CAAC;wBACxD;oBACF;oBACA,MAAM,QAAQ,MAAM,KAAA;oBAEpB,qBAAA,OAAA,KAAA,IAAA,kBAAmB,YAAA,CAAa,MAAM,QAAA;oBAGtC,IAAI,WAAW,OAAO;wBACpB,eAAe;wBACf,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO,MAAM,KAAA,CAAM,OAAA;wBAAQ,CAAC;wBAChE;oBACF;oBAEA,IAAI,cAAc;wBAChB,eAAe;wBAEf,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,GAAG,oBAAoB,KAAK,CAAA;wBAC9B,CAAC;oBACH;oBAEA,IAAI,MAAM,KAAA,IAAS,MAAM;wBACvB,QAAQ;4BACN,cAAA,CAAcA,MAAA,MAAM,KAAA,CAAM,aAAA,KAAZ,OAAAA,MAA6B,KAAA;4BAC3C,kBAAA,CAAkB,KAAA,MAAM,KAAA,CAAM,iBAAA,KAAZ,OAAA,KAAiC,KAAA;wBACrD;oBACF;oBAEA,MAAM,SAAS,MAAM,OAAA,CAAQ,CAAC,CAAA;oBAE9B,IAAA,CAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,aAAA,KAAiB,MAAM;wBACjC,eAAe,gCACb,OAAO,aAAA;oBAEX;oBAEA,IAAA,CAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,KAAA,KAAS,MAAM;wBACzB;oBACF;oBAEA,MAAM,QAAQ,OAAO,KAAA;oBAGrB,IAAI,MAAM,iBAAA,IAAqB,MAAM;wBACnC,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,WAAW,MAAM,iBAAA;wBACnB,CAAC;oBACH;oBAEA,IAAI,MAAM,OAAA,IAAW,MAAM;wBACzB,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,WAAW,MAAM,OAAA;wBACnB,CAAC;oBACH;oBAEA,IAAI,MAAM,UAAA,IAAc,MAAM;wBAC5B,KAAA,MAAW,iBAAiB,MAAM,UAAA,CAAY;4BAC5C,MAAM,QAAQ,cAAc,KAAA;4BAE5B,IAAI,SAAA,CAAU,KAAK,CAAA,IAAK,MAAM;gCAC5B,IAAI,cAAc,IAAA,KAAS,YAAY;oCACrC,MAAM,iKAAI,2BAAA,CAAyB;wCACjC,MAAM;wCACN,SAAS,CAAA,yBAAA,CAAA;oCACX,CAAC;gCACH;gCAEA,IAAI,cAAc,EAAA,IAAM,MAAM;oCAC5B,MAAM,iKAAI,2BAAA,CAAyB;wCACjC,MAAM;wCACN,SAAS,CAAA,6BAAA,CAAA;oCACX,CAAC;gCACH;gCAEA,IAAA,CAAA,CAAI,KAAA,cAAc,QAAA,KAAd,OAAA,KAAA,IAAA,GAAwB,IAAA,KAAQ,MAAM;oCACxC,MAAM,iKAAI,2BAAA,CAAyB;wCACjC,MAAM;wCACN,SAAS,CAAA,wCAAA,CAAA;oCACX,CAAC;gCACH;gCAEA,SAAA,CAAU,KAAK,CAAA,GAAI;oCACjB,IAAI,cAAc,EAAA;oCAClB,MAAM;oCACN,UAAU;wCACR,MAAM,cAAc,QAAA,CAAS,IAAA;wCAC7B,WAAA,CAAW,KAAA,cAAc,QAAA,CAAS,SAAA,KAAvB,OAAA,KAAoC;oCACjD;oCACA,aAAa;gCACf;gCAEA,MAAMC,YAAW,SAAA,CAAU,KAAK,CAAA;gCAEhC,IAAA,CAAA,CACE,KAAAA,UAAS,QAAA,KAAT,OAAA,KAAA,IAAA,GAAmB,IAAA,KAAQ,QAAA,CAAA,CAC3B,KAAAA,UAAS,QAAA,KAAT,OAAA,KAAA,IAAA,GAAmB,SAAA,KAAa,MAChC;oCAEA,IAAIA,UAAS,QAAA,CAAS,SAAA,CAAU,MAAA,GAAS,GAAG;wCAC1C,WAAW,OAAA,CAAQ;4CACjB,MAAM;4CACN,cAAc;4CACd,YAAYA,UAAS,EAAA;4CACrB,UAAUA,UAAS,QAAA,CAAS,IAAA;4CAC5B,eAAeA,UAAS,QAAA,CAAS,SAAA;wCACnC,CAAC;oCACH;oCAIA,8KAAI,iBAAA,EAAeA,UAAS,QAAA,CAAS,SAAS,GAAG;wCAC/C,WAAW,OAAA,CAAQ;4CACjB,MAAM;4CACN,cAAc;4CACd,YAAA,CAAY,KAAAA,UAAS,EAAA,KAAT,OAAA,+KAAe,aAAA,CAAW;4CACtC,UAAUA,UAAS,QAAA,CAAS,IAAA;4CAC5B,MAAMA,UAAS,QAAA,CAAS,SAAA;wCAC1B,CAAC;wCACDA,UAAS,WAAA,GAAc;oCACzB;gCACF;gCAEA;4BACF;4BAGA,MAAM,WAAW,SAAA,CAAU,KAAK,CAAA;4BAEhC,IAAI,SAAS,WAAA,EAAa;gCACxB;4BACF;4BAEA,IAAA,CAAA,CAAI,KAAA,cAAc,QAAA,KAAd,OAAA,KAAA,IAAA,GAAwB,SAAA,KAAa,MAAM;gCAC7C,SAAS,QAAA,CAAU,SAAA,IAAA,CACjB,KAAA,CAAA,KAAA,cAAc,QAAA,KAAd,OAAA,KAAA,IAAA,GAAwB,SAAA,KAAxB,OAAA,KAAqC;4BACzC;4BAGA,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,cAAc;gCACd,YAAY,SAAS,EAAA;gCACrB,UAAU,SAAS,QAAA,CAAS,IAAA;gCAC5B,eAAA,CAAe,KAAA,cAAc,QAAA,CAAS,SAAA,KAAvB,OAAA,KAAoC;4BACrD,CAAC;4BAGD,IAAA,CAAA,CACE,KAAA,SAAS,QAAA,KAAT,OAAA,KAAA,IAAA,GAAmB,IAAA,KAAQ,QAAA,CAAA,CAC3B,KAAA,SAAS,QAAA,KAAT,OAAA,KAAA,IAAA,GAAmB,SAAA,KAAa,kLAChC,iBAAA,EAAe,SAAS,QAAA,CAAS,SAAS,GAC1C;gCACA,WAAW,OAAA,CAAQ;oCACjB,MAAM;oCACN,cAAc;oCACd,YAAA,CAAY,KAAA,SAAS,EAAA,KAAT,OAAA,8KAAe,cAAA,CAAW;oCACtC,UAAU,SAAS,QAAA,CAAS,IAAA;oCAC5B,MAAM,SAAS,QAAA,CAAS,SAAA;gCAC1B,CAAC;gCACD,SAAS,WAAA,GAAc;4BACzB;wBACF;oBACF;gBACF;gBAEA,OAAM,UAAA,EAAY;oBA/iB5B,IAAAD,KAAA;oBAgjBY,MAAM,WAAW,qBAAA,OAAA,KAAA,IAAA,kBAAmB,aAAA;oBACpC,WAAW,OAAA,CAAQ;wBACjB,MAAM;wBACN;wBACA,OAAO;4BACL,cAAA,CAAcA,MAAA,MAAM,YAAA,KAAN,OAAAA,MAAsB;4BACpC,kBAAA,CAAkB,KAAA,MAAM,gBAAA,KAAN,OAAA,KAA0B;wBAC9C;wBACA,GAAI,YAAY;4BAAE,kBAAkB;wBAAS,CAAA;oBAC/C,CAAC;gBACH;YACF,CAAC;YAEH,SAAS;gBAAE;gBAAW;YAAY;YAClC,aAAa;gBAAE,SAAS;YAAgB;YACxC;YACA,SAAS;gBAAE;YAAK;QAClB;IACF;AACF;AAIA,IAAM,4KAAqCE,KAAAA,CAAE,MAAA,CAAO;IAClD,4IAAIA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACvB,iJAASA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC5B,+IAAOA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC1B,iJAASA,IAAAA,CAAE,KAAA,yIACTA,IAAAA,CAAE,MAAA,CAAO;QACP,iJAASA,IAAAA,CAAE,MAAA,CAAO;YAChB,8IAAMA,IAAAA,CAAE,OAAA,CAAQ,WAAW,EAAE,OAAA,CAAQ;YACrC,iJAASA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC5B,2JAAmBA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YACtC,oJAAYA,IAAAA,CACT,KAAA,yIACCA,IAAAA,CAAE,MAAA,CAAO;gBACP,4IAAIA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;gBACvB,8IAAMA,IAAAA,CAAE,OAAA,CAAQ,UAAU;gBAC1B,kJAAUA,IAAAA,CAAE,MAAA,CAAO;oBACjB,MAAMA,4IAAAA,CAAE,MAAA,CAAO;oBACf,mJAAWA,IAAAA,CAAE,MAAA,CAAO;gBACtB,CAAC;YACH,CAAC,GAEF,OAAA,CAAQ;QACb,CAAC;QACD,uJAAeA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACpC,CAAC;IAEH,+IAAOA,IAAAA,CACJ,MAAA,CAAO;QACN,uJAAeA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QAClC,2JAAmBA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACxC,CAAC,EACA,OAAA,CAAQ;AACb,CAAC;AAID,IAAM,wCAAwC,CAC5C,sJAEAA,IAAAA,CAAE,KAAA,CAAM;gJACNA,IAAAA,CAAE,MAAA,CAAO;YACP,4IAAIA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YACvB,iJAASA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC5B,+IAAOA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC1B,SAASA,4IAAAA,CAAE,KAAA,yIACTA,IAAAA,CAAE,MAAA,CAAO;gBACP,+IAAOA,IAAAA,CACJ,MAAA,CAAO;oBACN,8IAAMA,IAAAA,CAAE,IAAA,CAAK;wBAAC,WAAW;qBAAC,EAAE,OAAA,CAAQ;oBACpC,iJAASA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;oBAC5B,mBAAmBA,4IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;oBACtC,oJAAYA,IAAAA,CACT,KAAA,yIACCA,IAAAA,CAAE,MAAA,CAAO;wBACP,OAAOA,4IAAAA,CAAE,MAAA,CAAO;wBAChB,4IAAIA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;wBACvB,8IAAMA,IAAAA,CAAE,OAAA,CAAQ,UAAU,EAAE,QAAA,CAAS;wBACrC,kJAAUA,IAAAA,CAAE,MAAA,CAAO;4BACjB,8IAAMA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;4BACzB,mJAAWA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;wBAChC,CAAC;oBACH,CAAC,GAEF,OAAA,CAAQ;gBACb,CAAC,EACA,OAAA,CAAQ;gBACX,uJAAeA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YACpC,CAAC;YAEH,+IAAOA,IAAAA,CACJ,MAAA,CAAO;gBACN,uJAAeA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;gBAClC,2JAAmBA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YACxC,CAAC,EACA,OAAA,CAAQ;QACb,CAAC;QACD;KACD;;;;;AO9oBI,SAAS,0CAA0C,EACxD,MAAA,EACA,WAAA,EACA,OAAO,MAAA,EACP,YAAY,WAAA,EACd,EAQE;IAEA,IACE,gBAAgB,YAChB,OAAO,MAAA,KAAW,KAClB,MAAA,CAAO,CAAC,CAAA,CAAE,IAAA,KAAS,UACnB,MAAA,CAAO,CAAC,CAAA,CAAE,OAAA,CAAQ,MAAA,KAAW,KAC7B,MAAA,CAAO,CAAC,CAAA,CAAE,OAAA,CAAQ,CAAC,CAAA,CAAE,IAAA,KAAS,QAC9B;QACA,OAAO;YAAE,QAAQ,MAAA,CAAO,CAAC,CAAA,CAAE,OAAA,CAAQ,CAAC,CAAA,CAAE,IAAA;QAAK;IAC7C;IAGA,IAAI,OAAO;IAGX,IAAI,MAAA,CAAO,CAAC,CAAA,CAAE,IAAA,KAAS,UAAU;QAC/B,QAAQ,GAAG,MAAA,CAAO,CAAC,CAAA,CAAE,OAAO,CAAA;;AAAA,CAAA;QAC5B,SAAS,OAAO,KAAA,CAAM,CAAC;IACzB;IAEA,KAAA,MAAW,EAAE,IAAA,EAAM,OAAA,CAAQ,CAAA,IAAK,OAAQ;QACtC,OAAQ,MAAM;YACZ,KAAK;gBAAU;oBACb,MAAM,iKAAI,qBAAA,CAAmB;wBAC3B,SAAS;wBACT;oBACF,CAAC;gBACH;YAEA,KAAK;gBAAQ;oBACX,MAAM,cAAc,QACjB,GAAA,CAAI,CAAA,SAAQ;wBACX,OAAQ,KAAK,IAAA,EAAM;4BACjB,KAAK;gCAAQ;oCACX,OAAO,KAAK,IAAA;gCACd;4BACA,KAAK;gCAAS;oCACZ,MAAM,iKAAIQ,gCAAAA,CAA8B;wCACtC,eAAe;oCACjB,CAAC;gCACH;wBACF;oBACF,CAAC,EACA,IAAA,CAAK,EAAE;oBAEV,QAAQ,GAAG,IAAI,CAAA;AAAA,EAAM,WAAW,CAAA;;AAAA,CAAA;oBAChC;gBACF;YAEA,KAAK;gBAAa;oBAChB,MAAM,mBAAmB,QACtB,GAAA,CAAI,CAAA,SAAQ;wBACX,OAAQ,KAAK,IAAA,EAAM;4BACjB,KAAK;gCAAQ;oCACX,OAAO,KAAK,IAAA;gCACd;4BACA,KAAK;gCAAa;oCAChB,MAAM,iKAAIA,gCAAAA,CAA8B;wCACtC,eAAe;oCACjB,CAAC;gCACH;wBACF;oBACF,CAAC,EACA,IAAA,CAAK,EAAE;oBAEV,QAAQ,GAAG,SAAS,CAAA;AAAA,EAAM,gBAAgB,CAAA;;AAAA,CAAA;oBAC1C;gBACF;YAEA,KAAK;gBAAQ;oBACX,MAAM,iKAAIA,gCAAAA,CAA8B;wBACtC,eAAe;oBACjB,CAAC;gBACH;YAEA;gBAAS;oBACP,MAAM,mBAA0B;oBAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;gBACzD;QACF;IACF;IAGA,QAAQ,GAAG,SAAS,CAAA;AAAA,CAAA;IAEpB,OAAO;QACL,QAAQ;QACR,eAAe;YAAC,CAAA;AAAA,EAAK,IAAI,CAAA,CAAA,CAAG;SAAA;IAC9B;AACF;;ADtEO,IAAM,0CAAN,MAEP;IAAA,gCAAA;IAWE,YACE,OAAA,EACA,QAAA,EACA,MAAA,CACA;QAdF,IAAA,CAAS,oBAAA,GAAuB;QAChC,IAAA,CAAS,2BAAA,GAA8B,KAAA;QA3CzC,IAAA;QAyDI,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,MAAA,GAAS;QAGd,MAAM,iBAAA,CACJ,KAAA,OAAO,cAAA,KAAP,OAAA,KAAyB;QAC3B,IAAA,CAAK,WAAA,GAAc,4CACjB,eAAe,WAAA;QAEjB,IAAA,CAAK,qBAAA,6KAAwBC,iCAAAA,EAA+B,cAAc;IAC5E;IAEA,IAAI,WAAmB;QACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA;IACrB;IAEQ,QAAQ,EACd,IAAA,EACA,WAAA,EACA,MAAA,EACA,SAAA,EACA,WAAA,EACA,IAAA,EACA,IAAA,EACA,gBAAA,EACA,eAAA,EACA,eAAe,iBAAA,EACf,cAAA,EACA,IAAA,EACF,EAAiD;QAvFnD,IAAA;QAwFI,MAAM,OAAO,KAAK,IAAA;QAElB,MAAM,WAAyC,CAAC,CAAA;QAEhD,IAAI,QAAQ,MAAM;YAChB,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;YACX,CAAC;QACH;QAEA,IAAI,kBAAkB,QAAQ,eAAe,IAAA,KAAS,QAAQ;YAC5D,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;gBACT,SAAS;YACX,CAAC;QACH;QAEA,MAAM,EAAE,QAAQ,gBAAA,EAAkB,aAAA,CAAc,CAAA,GAC9C,0CAA0C;YAAE;YAAQ;QAAY,CAAC;QAEnE,MAAM,OAAO,CAAC;eAAI,iBAAA,OAAA,gBAAiB,CAAC,CAAA,EAAI;eAAI,qBAAA,OAAA,oBAAqB,CAAC,CAAE;SAAA;QAEpE,MAAM,WAAW;YAAA,YAAA;YAEf,OAAO,IAAA,CAAK,OAAA;YAAA,2BAAA;YAGZ,MAAM,IAAA,CAAK,QAAA,CAAS,IAAA;YACpB,YAAY,IAAA,CAAK,QAAA,CAAS,SAAA;YAC1B,QAAQ,IAAA,CAAK,QAAA,CAAS,MAAA;YACtB,MAAM,IAAA,CAAK,QAAA,CAAS,IAAA;YAAA,yBAAA;YAGpB,YAAY;YACZ;YACA,OAAO;YACP,mBAAmB;YACnB,kBAAkB;YAClB;YAAA,UAAA;YAGA,QAAQ;YAAA,kBAAA;YAGR,MAAM,KAAK,MAAA,GAAS,IAAI,OAAO,KAAA;QACjC;QAEA,OAAQ,MAAM;YACZ,KAAK;gBAAW;oBACd,IAAA,CAAI,KAAA,KAAK,KAAA,KAAL,OAAA,KAAA,IAAA,GAAY,MAAA,EAAQ;wBACtB,MAAM,iKAAIC,gCAAAA,CAA8B;4BACtC,eAAe;wBACjB,CAAC;oBACH;oBAEA,IAAI,KAAK,UAAA,EAAY;wBACnB,MAAM,iKAAIA,gCAAAA,CAA8B;4BACtC,eAAe;wBACjB,CAAC;oBACH;oBAEA,OAAO;wBAAE,MAAM;wBAAU;oBAAS;gBACpC;YAEA,KAAK;gBAAe;oBAClB,MAAM,iKAAIA,gCAAAA,CAA8B;wBACtC,eAAe;oBACjB,CAAC;gBACH;YAEA,KAAK;gBAAe;oBAClB,MAAM,IAAIA,6LAAAA,CAA8B;wBACtC,eAAe;oBACjB,CAAC;gBACH;YAEA;gBAAS;oBACP,MAAM,mBAA0B;oBAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;gBACzD;QACF;IACF;IAEA,MAAM,WACJ,OAAA,EAC6D;QA/KjE,IAAA,IAAA,IAAA,IAAA;QAgLI,MAAM,EAAE,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,IAAA,CAAK,OAAA,CAAQ,OAAO;QAE/C,MAAM,EAAE,eAAA,EAAiB,OAAO,QAAA,CAAS,CAAA,GAAI,gLAAMC,gBAAAA,EAAc;YAC/D,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,mLAASC,iBAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D,MAAM;YACN,uBAAuB,IAAA,CAAK,qBAAA;YAC5B,+BAA2BC,kMAAAA,EACzB;YAEF,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,MAAM,EAAE,QAAQ,SAAA,EAAW,GAAG,YAAY,CAAA,GAAI;QAC9C,MAAM,SAAS,SAAS,OAAA,CAAQ,CAAC,CAAA;QAEjC,OAAO;YACL,MAAM,OAAO,IAAA;YACb,OAAO;gBACL,cAAA,CAAc,KAAA,CAAA,KAAA,SAAS,KAAA,KAAT,OAAA,KAAA,IAAA,GAAgB,aAAA,KAAhB,OAAA,KAAiC;gBAC/C,kBAAA,CAAkB,KAAA,CAAA,KAAA,SAAS,KAAA,KAAT,OAAA,KAAA,IAAA,GAAgB,iBAAA,KAAhB,OAAA,KAAqC;YACzD;YACA,cAAc,gCAAgC,OAAO,aAAa;YAClE,SAAS;gBAAE;gBAAW;YAAY;YAClC,aAAa;gBAAE,SAAS;YAAgB;YACxC,UAAU,oBAAoB,QAAQ;YACtC;YACA,SAAS;gBAAE,MAAM,KAAK,SAAA,CAAU,IAAI;YAAE;QACxC;IACF;IAEA,MAAM,SACJ,OAAA,EAC2D;QAC3D,MAAM,EAAE,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,IAAA,CAAK,OAAA,CAAQ,OAAO;QAE/C,MAAM,OAAO;YACX,GAAG,IAAA;YACH,QAAQ;QACV;QAEA,MAAM,EAAE,eAAA,EAAiB,OAAO,QAAA,CAAS,CAAA,GAAI,gLAAMF,gBAAAA,EAAc;YAC/D,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,mLAASC,iBAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D;YACA,uBAAuB,IAAA,CAAK,qBAAA;YAC5B,qMAA2BE,mCAAAA,EACzB,IAAA,CAAK,WAAA;YAEP,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,MAAM,EAAE,QAAQ,SAAA,EAAW,GAAG,YAAY,CAAA,GAAI;QAE9C,IAAI,eAA4C;QAChD,IAAI,QAA4D;YAC9D,cAAc,OAAO,GAAA;YACrB,kBAAkB,OAAO,GAAA;QAC3B;QACA,IAAI,eAAe;QAEnB,OAAO;YACL,QAAQ,SAAS,WAAA,CACf,IAAI,gBAGF;gBACA,WAAU,KAAA,EAAO,UAAA,EAAY;oBAE3B,IAAI,CAAC,MAAM,OAAA,EAAS;wBAClB,eAAe;wBACf,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO,MAAM,KAAA;wBAAM,CAAC;wBACxD;oBACF;oBAEA,MAAM,QAAQ,MAAM,KAAA;oBAGpB,IAAI,WAAW,OAAO;wBACpB,eAAe;wBACf,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO,MAAM,KAAA;wBAAM,CAAC;wBACxD;oBACF;oBAEA,IAAI,cAAc;wBAChB,eAAe;wBAEf,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,GAAG,oBAAoB,KAAK,CAAA;wBAC9B,CAAC;oBACH;oBAEA,IAAI,MAAM,KAAA,IAAS,MAAM;wBACvB,QAAQ;4BACN,cAAc,MAAM,KAAA,CAAM,aAAA;4BAC1B,kBAAkB,MAAM,KAAA,CAAM,iBAAA;wBAChC;oBACF;oBAEA,MAAM,SAAS,MAAM,OAAA,CAAQ,CAAC,CAAA;oBAE9B,IAAA,CAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,aAAA,KAAiB,MAAM;wBACjC,eAAe,gCACb,OAAO,aAAA;oBAEX;oBAEA,IAAA,CAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,IAAA,KAAQ,MAAM;wBACxB,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,WAAW,OAAO,IAAA;wBACpB,CAAC;oBACH;gBACF;gBAEA,OAAM,UAAA,EAAY;oBAChB,WAAW,OAAA,CAAQ;wBACjB,MAAM;wBACN;wBACA;oBACF,CAAC;gBACH;YACF,CAAC;YAEH,SAAS;gBAAE;gBAAW;YAAY;YAClC,aAAa;gBAAE,SAAS;YAAgB;YACxC;YACA,SAAS;gBAAE,MAAM,KAAK,SAAA,CAAU,IAAI;YAAE;QACxC;IACF;AACF;AAIA,IAAM,mLAA2CC,IAAAA,CAAE,MAAA,CAAO;IACxD,4IAAIA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACvB,iJAASA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC5B,+IAAOA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC1B,gJAASA,KAAAA,CAAE,KAAA,yIACTA,IAAAA,CAAE,MAAA,CAAO;QACP,MAAMA,4IAAAA,CAAE,MAAA,CAAO;QACf,uJAAeA,IAAAA,CAAE,MAAA,CAAO;IAC1B,CAAC;IAEH,+IAAOA,IAAAA,CACJ,MAAA,CAAO;QACN,uJAAeA,IAAAA,CAAE,MAAA,CAAO;QACxB,0JAAmBA,KAAAA,CAAE,MAAA,CAAO;IAC9B,CAAC,EACA,OAAA,CAAQ;AACb,CAAC;AAID,IAAM,8CAA8C,CAGlD,sJAEAA,IAAAA,CAAE,KAAA,CAAM;gJACNA,IAAAA,CAAE,MAAA,CAAO;YACP,4IAAIA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YACvB,iJAASA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC5B,+IAAOA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC1B,SAASA,4IAAAA,CAAE,KAAA,yIACTA,IAAAA,CAAE,MAAA,CAAO;gBACP,8IAAMA,IAAAA,CAAE,MAAA,CAAO;gBACf,uJAAeA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;gBAClC,+IAAOA,IAAAA,CAAE,MAAA,CAAO;YAClB,CAAC;YAEH,+IAAOA,IAAAA,CACJ,MAAA,CAAO;gBACN,uJAAeA,IAAAA,CAAE,MAAA,CAAO;gBACxB,2JAAmBA,IAAAA,CAAE,MAAA,CAAO;YAC9B,CAAC,EACA,OAAA,CAAQ;QACb,CAAC;QACD;KACD;;;;AErUI,IAAM,iCAAN,MAEP;IAmBE,YACE,OAAA,EACA,QAAA,EACA,MAAA,CACA;QAtBF,IAAA,CAAS,oBAAA,GAAuB;QAuB9B,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,MAAA,GAAS;IAChB;IApBA,IAAI,WAAmB;QACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA;IACrB;IAEA,IAAI,uBAA+B;QApDrC,IAAA;QAqDI,OAAA,CAAO,KAAA,IAAA,CAAK,MAAA,CAAO,oBAAA,KAAZ,OAAA,KAAoC;IAC7C;IAEA,IAAI,wBAAiC;QAxDvC,IAAA;QAyDI,OAAA,CAAO,KAAA,IAAA,CAAK,MAAA,CAAO,qBAAA,KAAZ,OAAA,KAAqC;IAC9C;IAYA,MAAM,QAAQ,EACZ,MAAA,EACA,OAAA,EACA,WAAA,EACF,EAEE;QA5EJ,IAAA;QA6EI,IAAI,OAAO,MAAA,GAAS,IAAA,CAAK,oBAAA,EAAsB;YAC7C,MAAM,iKAAI,qCAAA,CAAmC;gBAC3C,UAAU,IAAA,CAAK,QAAA;gBACf,SAAS,IAAA,CAAK,OAAA;gBACd,sBAAsB,IAAA,CAAK,oBAAA;gBAC3B;YACF,CAAC;QACH;QAEA,MAAM,EAAE,eAAA,EAAiB,OAAO,QAAA,CAAS,CAAA,GAAI,gLAAMM,gBAAAA,EAAc;YAC/D,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,mLAASC,iBAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,OAAO;YACtD,MAAM;gBACJ,OAAO,IAAA,CAAK,OAAA;gBACZ,OAAO;gBACP,iBAAiB;gBACjB,YAAY,IAAA,CAAK,QAAA,CAAS,UAAA;gBAC1B,MAAM,IAAA,CAAK,QAAA,CAAS,IAAA;YACtB;YACA,iMAAuBC,iCAAAA,EAAA,CACrB,KAAA,IAAA,CAAK,MAAA,CAAO,cAAA,KAAZ,OAAA,KAA8B;YAEhC,+BAA2BC,kMAAAA,EACzB;YAEF;YACA,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,OAAO;YACL,YAAY,SAAS,IAAA,CAAK,GAAA,CAAI,CAAA,OAAQ,KAAK,SAAS;YACpD,OAAO,SAAS,KAAA,GACZ;gBAAE,QAAQ,SAAS,KAAA,CAAM,aAAA;YAAc,IACvC,KAAA;YACJ,aAAa;gBAAE,SAAS;YAAgB;QAC1C;IACF;AACF;AAIA,IAAM,oCAAoCC,4IAAAA,CAAE,MAAA,CAAO;IACjD,8IAAMA,IAAAA,CAAE,KAAA,yIAAMA,IAAAA,CAAE,MAAA,CAAO;QAAE,mJAAWA,IAAAA,CAAE,KAAA,wIAAMA,KAAAA,CAAE,MAAA,CAAO,CAAC;IAAE,CAAC,CAAC;IAC1D,+IAAOA,IAAAA,CAAE,MAAA,CAAO;QAAE,uJAAeA,IAAAA,CAAE,MAAA,CAAO;IAAE,CAAC,EAAE,OAAA,CAAQ;AACzD,CAAC;;ACrCM,SAAS,uBAKd,OAAA,EAKA;IACA,IAAI,CAAC,QAAQ,OAAA,EAAS;QACpB,MAAM,IAAI,MAAM,sBAAsB;IACxC;IACA,MAAM,UAAU,iMAAA,EAAqB,QAAQ,OAAO;IAEpD,IAAI,CAAC,QAAQ,IAAA,EAAM;QACjB,MAAM,IAAI,MAAM,2BAA2B;IAC7C;IACA,MAAM,eAAe,QAAQ,IAAA;IAS7B,MAAM,aAAa,IAAA,CAAO;YACxB,GAAI,QAAQ,MAAA,IAAU;gBAAE,eAAe,CAAA,OAAA,EAAU,QAAQ,MAAM,EAAA;YAAG,CAAA;YAClE,GAAG,QAAQ,OAAA;QACb,CAAA;IAEA,MAAM,uBAAuB,CAAC,YAAA,CAA0C;YACtE,UAAU,GAAG,YAAY,CAAA,CAAA,EAAI,SAAS,EAAA;YACtC,KAAK,CAAC,EAAE,IAAA,CAAK,CAAA,KAAM;gBACjB,MAAM,MAAM,IAAI,IAAI,GAAG,OAAO,GAAG,IAAI,EAAE;gBACvC,IAAI,QAAQ,WAAA,EAAa;oBACvB,IAAI,MAAA,GAAS,IAAI,gBAAgB,QAAQ,WAAW,EAAE,QAAA,CAAS;gBACjE;gBACA,OAAO,IAAI,QAAA,CAAS;YACtB;YACA,SAAS;YACT,OAAO,QAAQ,KAAA;QACjB,CAAA;IAEA,MAAM,sBAAsB,CAC1B,SACA,WAAyC,CAAC,CAAA,GACvC,gBAAgB,SAAS,QAAQ;IAEtC,MAAM,kBAAkB,CACtB,SACA,WAAyC,CAAC,CAAA,GAE1C,IAAI,kCAAkC,SAAS,UAAU;YACvD,GAAG,qBAAqB,MAAM,CAAA;YAC9B,6BAA6B;QAC/B,CAAC;IAEH,MAAM,wBAAwB,CAC5B,SACA,WAA+C,CAAC,CAAA,GAEhD,IAAI,wCACF,SACA,UACA,qBAAqB,YAAY;IAGrC,MAAM,uBAAuB,CAC3B,SACA,WAA8C,CAAC,CAAA,GAE/C,IAAI,+BACF,SACA,UACA,qBAAqB,WAAW;IAGpC,MAAM,WAAW,CACf,SACA,WACG,oBAAoB,SAAS,QAAQ;IAE1C,SAAS,aAAA,GAAgB;IACzB,SAAS,SAAA,GAAY;IACrB,SAAS,eAAA,GAAkB;IAC3B,SAAS,kBAAA,GAAqB;IAE9B,OAAO;AAKT","ignoreList":[0,1,2,3,4,5,6,7,8,9],"debugId":null}},
    {"offset": {"line": 1216, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1222, "column": 0}, "map": {"version":3,"sources":["file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/xai/node_modules/%40ai-sdk/openai-compatible/src/openai-compatible-chat-language-model.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/xai/node_modules/%40ai-sdk/openai-compatible/src/convert-to-openai-compatible-chat-messages.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/xai/node_modules/%40ai-sdk/openai-compatible/src/get-response-metadata.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/xai/node_modules/%40ai-sdk/openai-compatible/src/map-openai-compatible-finish-reason.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/xai/node_modules/%40ai-sdk/openai-compatible/src/openai-compatible-error.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/xai/node_modules/%40ai-sdk/openai-compatible/src/openai-compatible-prepare-tools.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/xai/node_modules/%40ai-sdk/openai-compatible/src/openai-compatible-completion-language-model.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/xai/node_modules/%40ai-sdk/openai-compatible/src/convert-to-openai-compatible-completion-prompt.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/xai/node_modules/%40ai-sdk/openai-compatible/src/openai-compatible-embedding-model.ts","file:///home/ubuntu/searchBasedRAG/node_modules/%40ai-sdk/xai/node_modules/%40ai-sdk/openai-compatible/src/openai-compatible-provider.ts"],"sourcesContent":["import {\n  APICallError,\n  InvalidResponseDataError,\n  LanguageModelV1,\n  LanguageModelV1CallWarning,\n  LanguageModelV1FinishReason,\n  LanguageModelV1ObjectGenerationMode,\n  LanguageModelV1StreamPart,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonErrorResponseHandler,\n  createJsonResponseHandler,\n  FetchFunction,\n  generateId,\n  isParsableJson,\n  ParseResult,\n  postJsonToApi,\n  ResponseHandler,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\nimport { convertToOpenAICompatibleChatMessages } from './convert-to-openai-compatible-chat-messages';\nimport { getResponseMetadata } from './get-response-metadata';\nimport { mapOpenAICompatibleFinishReason } from './map-openai-compatible-finish-reason';\nimport {\n  OpenAICompatibleChatModelId,\n  OpenAICompatibleChatSettings,\n} from './openai-compatible-chat-settings';\nimport {\n  defaultOpenAICompatibleErrorStructure,\n  ProviderErrorStructure,\n} from './openai-compatible-error';\nimport { prepareTools } from './openai-compatible-prepare-tools';\nimport { MetadataExtractor } from './openai-compatible-metadata-extractor';\n\nexport type OpenAICompatibleChatConfig = {\n  provider: string;\n  headers: () => Record<string, string | undefined>;\n  url: (options: { modelId: string; path: string }) => string;\n  fetch?: FetchFunction;\n  errorStructure?: ProviderErrorStructure<any>;\n  metadataExtractor?: MetadataExtractor;\n\n  /**\nDefault object generation mode that should be used with this model when\nno mode is specified. Should be the mode with the best results for this\nmodel. `undefined` can be specified if object generation is not supported.\n  */\n  defaultObjectGenerationMode?: LanguageModelV1ObjectGenerationMode;\n\n  /**\n   * Whether the model supports structured outputs.\n   */\n  supportsStructuredOutputs?: boolean;\n};\n\nexport class OpenAICompatibleChatLanguageModel implements LanguageModelV1 {\n  readonly specificationVersion = 'v1';\n\n  readonly supportsStructuredOutputs: boolean;\n\n  readonly modelId: OpenAICompatibleChatModelId;\n  readonly settings: OpenAICompatibleChatSettings;\n\n  private readonly config: OpenAICompatibleChatConfig;\n  private readonly failedResponseHandler: ResponseHandler<APICallError>;\n  private readonly chunkSchema; // type inferred via constructor\n\n  constructor(\n    modelId: OpenAICompatibleChatModelId,\n    settings: OpenAICompatibleChatSettings,\n    config: OpenAICompatibleChatConfig,\n  ) {\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n\n    // initialize error handling:\n    const errorStructure =\n      config.errorStructure ?? defaultOpenAICompatibleErrorStructure;\n    this.chunkSchema = createOpenAICompatibleChatChunkSchema(\n      errorStructure.errorSchema,\n    );\n    this.failedResponseHandler = createJsonErrorResponseHandler(errorStructure);\n\n    this.supportsStructuredOutputs = config.supportsStructuredOutputs ?? false;\n  }\n\n  get defaultObjectGenerationMode(): 'json' | 'tool' | undefined {\n    return this.config.defaultObjectGenerationMode;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private get providerOptionsName(): string {\n    return this.config.provider.split('.')[0].trim();\n  }\n\n  private getArgs({\n    mode,\n    prompt,\n    maxTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    providerMetadata,\n    stopSequences,\n    responseFormat,\n    seed,\n  }: Parameters<LanguageModelV1['doGenerate']>[0]) {\n    const type = mode.type;\n\n    const warnings: LanguageModelV1CallWarning[] = [];\n\n    if (topK != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'topK',\n      });\n    }\n\n    if (\n      responseFormat?.type === 'json' &&\n      responseFormat.schema != null &&\n      !this.supportsStructuredOutputs\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'responseFormat',\n        details:\n          'JSON response format schema is only supported with structuredOutputs',\n      });\n    }\n\n    const baseArgs = {\n      // model id:\n      model: this.modelId,\n\n      // model specific settings:\n      user: this.settings.user,\n\n      // standardized settings:\n      max_tokens: maxTokens,\n      temperature,\n      top_p: topP,\n      frequency_penalty: frequencyPenalty,\n      presence_penalty: presencePenalty,\n      response_format:\n        responseFormat?.type === 'json'\n          ? this.supportsStructuredOutputs === true &&\n            responseFormat.schema != null\n            ? {\n                type: 'json_schema',\n                json_schema: {\n                  schema: responseFormat.schema,\n                  name: responseFormat.name ?? 'response',\n                  description: responseFormat.description,\n                },\n              }\n            : { type: 'json_object' }\n          : undefined,\n\n      stop: stopSequences,\n      seed,\n      ...providerMetadata?.[this.providerOptionsName],\n\n      // messages:\n      messages: convertToOpenAICompatibleChatMessages(prompt),\n    };\n\n    switch (type) {\n      case 'regular': {\n        const { tools, tool_choice, toolWarnings } = prepareTools({\n          mode,\n          structuredOutputs: this.supportsStructuredOutputs,\n        });\n\n        return {\n          args: { ...baseArgs, tools, tool_choice },\n          warnings: [...warnings, ...toolWarnings],\n        };\n      }\n\n      case 'object-json': {\n        return {\n          args: {\n            ...baseArgs,\n            response_format:\n              this.supportsStructuredOutputs === true && mode.schema != null\n                ? {\n                    type: 'json_schema',\n                    json_schema: {\n                      schema: mode.schema,\n                      name: mode.name ?? 'response',\n                      description: mode.description,\n                    },\n                  }\n                : { type: 'json_object' },\n          },\n          warnings,\n        };\n      }\n\n      case 'object-tool': {\n        return {\n          args: {\n            ...baseArgs,\n            tool_choice: {\n              type: 'function',\n              function: { name: mode.tool.name },\n            },\n            tools: [\n              {\n                type: 'function',\n                function: {\n                  name: mode.tool.name,\n                  description: mode.tool.description,\n                  parameters: mode.tool.parameters,\n                },\n              },\n            ],\n          },\n          warnings,\n        };\n      }\n\n      default: {\n        const _exhaustiveCheck: never = type;\n        throw new Error(`Unsupported type: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV1['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV1['doGenerate']>>> {\n    const { args, warnings } = this.getArgs({ ...options });\n\n    const body = JSON.stringify(args);\n\n    const {\n      responseHeaders,\n      value: responseBody,\n      rawValue: parsedBody,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/chat/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: args,\n      failedResponseHandler: this.failedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        OpenAICompatibleChatResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const { messages: rawPrompt, ...rawSettings } = args;\n    const choice = responseBody.choices[0];\n    const providerMetadata = this.config.metadataExtractor?.extractMetadata?.({\n      parsedBody,\n    });\n\n    return {\n      text: choice.message.content ?? undefined,\n      reasoning: choice.message.reasoning_content ?? undefined,\n      toolCalls: choice.message.tool_calls?.map(toolCall => ({\n        toolCallType: 'function',\n        toolCallId: toolCall.id ?? generateId(),\n        toolName: toolCall.function.name,\n        args: toolCall.function.arguments!,\n      })),\n      finishReason: mapOpenAICompatibleFinishReason(choice.finish_reason),\n      usage: {\n        promptTokens: responseBody.usage?.prompt_tokens ?? NaN,\n        completionTokens: responseBody.usage?.completion_tokens ?? NaN,\n      },\n      ...(providerMetadata && { providerMetadata }),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      response: getResponseMetadata(responseBody),\n      warnings,\n      request: { body },\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV1['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV1['doStream']>>> {\n    if (this.settings.simulateStreaming) {\n      const result = await this.doGenerate(options);\n      const simulatedStream = new ReadableStream<LanguageModelV1StreamPart>({\n        start(controller) {\n          controller.enqueue({ type: 'response-metadata', ...result.response });\n          if (result.reasoning) {\n            controller.enqueue({\n              type: 'reasoning',\n              textDelta: result.reasoning,\n            });\n          }\n          if (result.text) {\n            controller.enqueue({\n              type: 'text-delta',\n              textDelta: result.text,\n            });\n          }\n          if (result.toolCalls) {\n            for (const toolCall of result.toolCalls) {\n              controller.enqueue({\n                type: 'tool-call',\n                ...toolCall,\n              });\n            }\n          }\n          controller.enqueue({\n            type: 'finish',\n            finishReason: result.finishReason,\n            usage: result.usage,\n            logprobs: result.logprobs,\n            providerMetadata: result.providerMetadata,\n          });\n          controller.close();\n        },\n      });\n      return {\n        stream: simulatedStream,\n        rawCall: result.rawCall,\n        rawResponse: result.rawResponse,\n        warnings: result.warnings,\n      };\n    }\n\n    const { args, warnings } = this.getArgs({ ...options });\n\n    const body = JSON.stringify({ ...args, stream: true });\n    const metadataExtractor =\n      this.config.metadataExtractor?.createStreamExtractor();\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/chat/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: {\n        ...args,\n        stream: true,\n      },\n      failedResponseHandler: this.failedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        this.chunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const { messages: rawPrompt, ...rawSettings } = args;\n\n    const toolCalls: Array<{\n      id: string;\n      type: 'function';\n      function: {\n        name: string;\n        arguments: string;\n      };\n      hasFinished: boolean;\n    }> = [];\n\n    let finishReason: LanguageModelV1FinishReason = 'unknown';\n    let usage: {\n      promptTokens: number | undefined;\n      completionTokens: number | undefined;\n    } = {\n      promptTokens: undefined,\n      completionTokens: undefined,\n    };\n    let isFirstChunk = true;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<z.infer<typeof this.chunkSchema>>,\n          LanguageModelV1StreamPart\n        >({\n          // TODO we lost type safety on Chunk, most likely due to the error schema. MUST FIX\n          transform(chunk, controller) {\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n            const value = chunk.value;\n\n            metadataExtractor?.processChunk(chunk.rawValue);\n\n            // handle error chunks:\n            if ('error' in value) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: value.error.message });\n              return;\n            }\n\n            if (isFirstChunk) {\n              isFirstChunk = false;\n\n              controller.enqueue({\n                type: 'response-metadata',\n                ...getResponseMetadata(value),\n              });\n            }\n\n            if (value.usage != null) {\n              usage = {\n                promptTokens: value.usage.prompt_tokens ?? undefined,\n                completionTokens: value.usage.completion_tokens ?? undefined,\n              };\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = mapOpenAICompatibleFinishReason(\n                choice.finish_reason,\n              );\n            }\n\n            if (choice?.delta == null) {\n              return;\n            }\n\n            const delta = choice.delta;\n\n            // enqueue reasoning before text deltas:\n            if (delta.reasoning_content != null) {\n              controller.enqueue({\n                type: 'reasoning',\n                textDelta: delta.reasoning_content,\n              });\n            }\n\n            if (delta.content != null) {\n              controller.enqueue({\n                type: 'text-delta',\n                textDelta: delta.content,\n              });\n            }\n\n            if (delta.tool_calls != null) {\n              for (const toolCallDelta of delta.tool_calls) {\n                const index = toolCallDelta.index;\n\n                if (toolCalls[index] == null) {\n                  if (toolCallDelta.type !== 'function') {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function' type.`,\n                    });\n                  }\n\n                  if (toolCallDelta.id == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'id' to be a string.`,\n                    });\n                  }\n\n                  if (toolCallDelta.function?.name == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function.name' to be a string.`,\n                    });\n                  }\n\n                  toolCalls[index] = {\n                    id: toolCallDelta.id,\n                    type: 'function',\n                    function: {\n                      name: toolCallDelta.function.name,\n                      arguments: toolCallDelta.function.arguments ?? '',\n                    },\n                    hasFinished: false,\n                  };\n\n                  const toolCall = toolCalls[index];\n\n                  if (\n                    toolCall.function?.name != null &&\n                    toolCall.function?.arguments != null\n                  ) {\n                    // send delta if the argument text has already started:\n                    if (toolCall.function.arguments.length > 0) {\n                      controller.enqueue({\n                        type: 'tool-call-delta',\n                        toolCallType: 'function',\n                        toolCallId: toolCall.id,\n                        toolName: toolCall.function.name,\n                        argsTextDelta: toolCall.function.arguments,\n                      });\n                    }\n\n                    // check if tool call is complete\n                    // (some providers send the full tool call in one chunk):\n                    if (isParsableJson(toolCall.function.arguments)) {\n                      controller.enqueue({\n                        type: 'tool-call',\n                        toolCallType: 'function',\n                        toolCallId: toolCall.id ?? generateId(),\n                        toolName: toolCall.function.name,\n                        args: toolCall.function.arguments,\n                      });\n                      toolCall.hasFinished = true;\n                    }\n                  }\n\n                  continue;\n                }\n\n                // existing tool call, merge if not finished\n                const toolCall = toolCalls[index];\n\n                if (toolCall.hasFinished) {\n                  continue;\n                }\n\n                if (toolCallDelta.function?.arguments != null) {\n                  toolCall.function!.arguments +=\n                    toolCallDelta.function?.arguments ?? '';\n                }\n\n                // send delta\n                controller.enqueue({\n                  type: 'tool-call-delta',\n                  toolCallType: 'function',\n                  toolCallId: toolCall.id,\n                  toolName: toolCall.function.name,\n                  argsTextDelta: toolCallDelta.function.arguments ?? '',\n                });\n\n                // check if tool call is complete\n                if (\n                  toolCall.function?.name != null &&\n                  toolCall.function?.arguments != null &&\n                  isParsableJson(toolCall.function.arguments)\n                ) {\n                  controller.enqueue({\n                    type: 'tool-call',\n                    toolCallType: 'function',\n                    toolCallId: toolCall.id ?? generateId(),\n                    toolName: toolCall.function.name,\n                    args: toolCall.function.arguments,\n                  });\n                  toolCall.hasFinished = true;\n                }\n              }\n            }\n          },\n\n          flush(controller) {\n            const metadata = metadataExtractor?.buildMetadata();\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage: {\n                promptTokens: usage.promptTokens ?? NaN,\n                completionTokens: usage.completionTokens ?? NaN,\n              },\n              ...(metadata && { providerMetadata: metadata }),\n            });\n          },\n        }),\n      ),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      warnings,\n      request: { body },\n    };\n  }\n}\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst OpenAICompatibleChatResponseSchema = z.object({\n  id: z.string().nullish(),\n  created: z.number().nullish(),\n  model: z.string().nullish(),\n  choices: z.array(\n    z.object({\n      message: z.object({\n        role: z.literal('assistant').nullish(),\n        content: z.string().nullish(),\n        reasoning_content: z.string().nullish(),\n        tool_calls: z\n          .array(\n            z.object({\n              id: z.string().nullish(),\n              type: z.literal('function'),\n              function: z.object({\n                name: z.string(),\n                arguments: z.string(),\n              }),\n            }),\n          )\n          .nullish(),\n      }),\n      finish_reason: z.string().nullish(),\n    }),\n  ),\n  usage: z\n    .object({\n      prompt_tokens: z.number().nullish(),\n      completion_tokens: z.number().nullish(),\n    })\n    .nullish(),\n});\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst createOpenAICompatibleChatChunkSchema = <ERROR_SCHEMA extends z.ZodType>(\n  errorSchema: ERROR_SCHEMA,\n) =>\n  z.union([\n    z.object({\n      id: z.string().nullish(),\n      created: z.number().nullish(),\n      model: z.string().nullish(),\n      choices: z.array(\n        z.object({\n          delta: z\n            .object({\n              role: z.enum(['assistant']).nullish(),\n              content: z.string().nullish(),\n              reasoning_content: z.string().nullish(),\n              tool_calls: z\n                .array(\n                  z.object({\n                    index: z.number(),\n                    id: z.string().nullish(),\n                    type: z.literal('function').optional(),\n                    function: z.object({\n                      name: z.string().nullish(),\n                      arguments: z.string().nullish(),\n                    }),\n                  }),\n                )\n                .nullish(),\n            })\n            .nullish(),\n          finish_reason: z.string().nullish(),\n        }),\n      ),\n      usage: z\n        .object({\n          prompt_tokens: z.number().nullish(),\n          completion_tokens: z.number().nullish(),\n        })\n        .nullish(),\n    }),\n    errorSchema,\n  ]);\n","import {\n  LanguageModelV1Prompt,\n  LanguageModelV1ProviderMetadata,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { convertUint8ArrayToBase64 } from '@ai-sdk/provider-utils';\nimport { OpenAICompatibleChatPrompt } from './openai-compatible-api-types';\n\nfunction getOpenAIMetadata(message: {\n  providerMetadata?: LanguageModelV1ProviderMetadata;\n}) {\n  return message?.providerMetadata?.openaiCompatible ?? {};\n}\n\nexport function convertToOpenAICompatibleChatMessages(\n  prompt: LanguageModelV1Prompt,\n): OpenAICompatibleChatPrompt {\n  const messages: OpenAICompatibleChatPrompt = [];\n  for (const { role, content, ...message } of prompt) {\n    const metadata = getOpenAIMetadata({ ...message });\n    switch (role) {\n      case 'system': {\n        messages.push({ role: 'system', content, ...metadata });\n        break;\n      }\n\n      case 'user': {\n        if (content.length === 1 && content[0].type === 'text') {\n          messages.push({\n            role: 'user',\n            content: content[0].text,\n            ...getOpenAIMetadata(content[0]),\n          });\n          break;\n        }\n\n        messages.push({\n          role: 'user',\n          content: content.map(part => {\n            const partMetadata = getOpenAIMetadata(part);\n            switch (part.type) {\n              case 'text': {\n                return { type: 'text', text: part.text, ...partMetadata };\n              }\n              case 'image': {\n                return {\n                  type: 'image_url',\n                  image_url: {\n                    url:\n                      part.image instanceof URL\n                        ? part.image.toString()\n                        : `data:${\n                            part.mimeType ?? 'image/jpeg'\n                          };base64,${convertUint8ArrayToBase64(part.image)}`,\n                  },\n                  ...partMetadata,\n                };\n              }\n              case 'file': {\n                throw new UnsupportedFunctionalityError({\n                  functionality: 'File content parts in user messages',\n                });\n              }\n            }\n          }),\n          ...metadata,\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        let text = '';\n        const toolCalls: Array<{\n          id: string;\n          type: 'function';\n          function: { name: string; arguments: string };\n        }> = [];\n\n        for (const part of content) {\n          const partMetadata = getOpenAIMetadata(part);\n          switch (part.type) {\n            case 'text': {\n              text += part.text;\n              break;\n            }\n            case 'tool-call': {\n              toolCalls.push({\n                id: part.toolCallId,\n                type: 'function',\n                function: {\n                  name: part.toolName,\n                  arguments: JSON.stringify(part.args),\n                },\n                ...partMetadata,\n              });\n              break;\n            }\n            default: {\n              const _exhaustiveCheck: never = part;\n              throw new Error(`Unsupported part: ${_exhaustiveCheck}`);\n            }\n          }\n        }\n\n        messages.push({\n          role: 'assistant',\n          content: text,\n          tool_calls: toolCalls.length > 0 ? toolCalls : undefined,\n          ...metadata,\n        });\n\n        break;\n      }\n\n      case 'tool': {\n        for (const toolResponse of content) {\n          const toolResponseMetadata = getOpenAIMetadata(toolResponse);\n          messages.push({\n            role: 'tool',\n            tool_call_id: toolResponse.toolCallId,\n            content: JSON.stringify(toolResponse.result),\n            ...toolResponseMetadata,\n          });\n        }\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  return messages;\n}\n","export function getResponseMetadata({\n  id,\n  model,\n  created,\n}: {\n  id?: string | undefined | null;\n  created?: number | undefined | null;\n  model?: string | undefined | null;\n}) {\n  return {\n    id: id ?? undefined,\n    modelId: model ?? undefined,\n    timestamp: created != null ? new Date(created * 1000) : undefined,\n  };\n}\n","import { LanguageModelV1FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAICompatibleFinishReason(\n  finishReason: string | null | undefined,\n): LanguageModelV1FinishReason {\n  switch (finishReason) {\n    case 'stop':\n      return 'stop';\n    case 'length':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    case 'function_call':\n    case 'tool_calls':\n      return 'tool-calls';\n    default:\n      return 'unknown';\n  }\n}\n","import { z, ZodSchema } from 'zod';\n\nexport const openaiCompatibleErrorDataSchema = z.object({\n  error: z.object({\n    message: z.string(),\n\n    // The additional information below is handled loosely to support\n    // OpenAI-compatible providers that have slightly different error\n    // responses:\n    type: z.string().nullish(),\n    param: z.any().nullish(),\n    code: z.union([z.string(), z.number()]).nullish(),\n  }),\n});\n\nexport type OpenAICompatibleErrorData = z.infer<\n  typeof openaiCompatibleErrorDataSchema\n>;\n\nexport type ProviderErrorStructure<T> = {\n  errorSchema: ZodSchema<T>;\n  errorToMessage: (error: T) => string;\n  isRetryable?: (response: Response, error?: T) => boolean;\n};\n\nexport const defaultOpenAICompatibleErrorStructure: ProviderErrorStructure<OpenAICompatibleErrorData> =\n  {\n    errorSchema: openaiCompatibleErrorDataSchema,\n    errorToMessage: data => data.error.message,\n  };\n","import {\n  LanguageModelV1,\n  LanguageModelV1CallWarning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\n\nexport function prepareTools({\n  mode,\n  structuredOutputs,\n}: {\n  mode: Parameters<LanguageModelV1['doGenerate']>[0]['mode'] & {\n    type: 'regular';\n  };\n  structuredOutputs: boolean;\n}): {\n  tools:\n    | undefined\n    | Array<{\n        type: 'function';\n        function: {\n          name: string;\n          description: string | undefined;\n          parameters: unknown;\n        };\n      }>;\n  tool_choice:\n    | { type: 'function'; function: { name: string } }\n    | 'auto'\n    | 'none'\n    | 'required'\n    | undefined;\n  toolWarnings: LanguageModelV1CallWarning[];\n} {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  const tools = mode.tools?.length ? mode.tools : undefined;\n  const toolWarnings: LanguageModelV1CallWarning[] = [];\n\n  if (tools == null) {\n    return { tools: undefined, tool_choice: undefined, toolWarnings };\n  }\n\n  const toolChoice = mode.toolChoice;\n\n  const openaiCompatTools: Array<{\n    type: 'function';\n    function: {\n      name: string;\n      description: string | undefined;\n      parameters: unknown;\n    };\n  }> = [];\n\n  for (const tool of tools) {\n    if (tool.type === 'provider-defined') {\n      toolWarnings.push({ type: 'unsupported-tool', tool });\n    } else {\n      openaiCompatTools.push({\n        type: 'function',\n        function: {\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.parameters,\n        },\n      });\n    }\n  }\n\n  if (toolChoice == null) {\n    return { tools: openaiCompatTools, tool_choice: undefined, toolWarnings };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n    case 'none':\n    case 'required':\n      return { tools: openaiCompatTools, tool_choice: type, toolWarnings };\n    case 'tool':\n      return {\n        tools: openaiCompatTools,\n        tool_choice: {\n          type: 'function',\n          function: {\n            name: toolChoice.toolName,\n          },\n        },\n        toolWarnings,\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new UnsupportedFunctionalityError({\n        functionality: `Unsupported tool choice type: ${_exhaustiveCheck}`,\n      });\n    }\n  }\n}\n","import {\n  APICallError,\n  LanguageModelV1,\n  LanguageModelV1CallWarning,\n  LanguageModelV1FinishReason,\n  LanguageModelV1StreamPart,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonErrorResponseHandler,\n  createJsonResponseHandler,\n  FetchFunction,\n  ParseResult,\n  postJsonToApi,\n  ResponseHandler,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\nimport { convertToOpenAICompatibleCompletionPrompt } from './convert-to-openai-compatible-completion-prompt';\nimport { getResponseMetadata } from './get-response-metadata';\nimport { mapOpenAICompatibleFinishReason } from './map-openai-compatible-finish-reason';\nimport {\n  OpenAICompatibleCompletionModelId,\n  OpenAICompatibleCompletionSettings,\n} from './openai-compatible-completion-settings';\nimport {\n  defaultOpenAICompatibleErrorStructure,\n  ProviderErrorStructure,\n} from './openai-compatible-error';\n\ntype OpenAICompatibleCompletionConfig = {\n  provider: string;\n  headers: () => Record<string, string | undefined>;\n  url: (options: { modelId: string; path: string }) => string;\n  fetch?: FetchFunction;\n  errorStructure?: ProviderErrorStructure<any>;\n};\n\nexport class OpenAICompatibleCompletionLanguageModel\n  implements LanguageModelV1\n{\n  readonly specificationVersion = 'v1';\n  readonly defaultObjectGenerationMode = undefined;\n\n  readonly modelId: OpenAICompatibleCompletionModelId;\n  readonly settings: OpenAICompatibleCompletionSettings;\n\n  private readonly config: OpenAICompatibleCompletionConfig;\n  private readonly failedResponseHandler: ResponseHandler<APICallError>;\n  private readonly chunkSchema; // type inferred via constructor\n\n  constructor(\n    modelId: OpenAICompatibleCompletionModelId,\n    settings: OpenAICompatibleCompletionSettings,\n    config: OpenAICompatibleCompletionConfig,\n  ) {\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n\n    // initialize error handling:\n    const errorStructure =\n      config.errorStructure ?? defaultOpenAICompatibleErrorStructure;\n    this.chunkSchema = createOpenAICompatibleCompletionChunkSchema(\n      errorStructure.errorSchema,\n    );\n    this.failedResponseHandler = createJsonErrorResponseHandler(errorStructure);\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private get providerOptionsName(): string {\n    return this.config.provider.split('.')[0].trim();\n  }\n\n  private getArgs({\n    mode,\n    inputFormat,\n    prompt,\n    maxTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences: userStopSequences,\n    responseFormat,\n    seed,\n    providerMetadata,\n  }: Parameters<LanguageModelV1['doGenerate']>[0]) {\n    const type = mode.type;\n\n    const warnings: LanguageModelV1CallWarning[] = [];\n\n    if (topK != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'topK',\n      });\n    }\n\n    if (responseFormat != null && responseFormat.type !== 'text') {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'responseFormat',\n        details: 'JSON response format is not supported.',\n      });\n    }\n\n    const { prompt: completionPrompt, stopSequences } =\n      convertToOpenAICompatibleCompletionPrompt({ prompt, inputFormat });\n\n    const stop = [...(stopSequences ?? []), ...(userStopSequences ?? [])];\n\n    const baseArgs = {\n      // model id:\n      model: this.modelId,\n\n      // model specific settings:\n      echo: this.settings.echo,\n      logit_bias: this.settings.logitBias,\n      suffix: this.settings.suffix,\n      user: this.settings.user,\n\n      // standardized settings:\n      max_tokens: maxTokens,\n      temperature,\n      top_p: topP,\n      frequency_penalty: frequencyPenalty,\n      presence_penalty: presencePenalty,\n      seed,\n      ...providerMetadata?.[this.providerOptionsName],\n\n      // prompt:\n      prompt: completionPrompt,\n\n      // stop sequences:\n      stop: stop.length > 0 ? stop : undefined,\n    };\n\n    switch (type) {\n      case 'regular': {\n        if (mode.tools?.length) {\n          throw new UnsupportedFunctionalityError({\n            functionality: 'tools',\n          });\n        }\n\n        if (mode.toolChoice) {\n          throw new UnsupportedFunctionalityError({\n            functionality: 'toolChoice',\n          });\n        }\n\n        return { args: baseArgs, warnings };\n      }\n\n      case 'object-json': {\n        throw new UnsupportedFunctionalityError({\n          functionality: 'object-json mode',\n        });\n      }\n\n      case 'object-tool': {\n        throw new UnsupportedFunctionalityError({\n          functionality: 'object-tool mode',\n        });\n      }\n\n      default: {\n        const _exhaustiveCheck: never = type;\n        throw new Error(`Unsupported type: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV1['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV1['doGenerate']>>> {\n    const { args, warnings } = this.getArgs(options);\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: args,\n      failedResponseHandler: this.failedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiCompatibleCompletionResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const { prompt: rawPrompt, ...rawSettings } = args;\n    const choice = response.choices[0];\n\n    return {\n      text: choice.text,\n      usage: {\n        promptTokens: response.usage?.prompt_tokens ?? NaN,\n        completionTokens: response.usage?.completion_tokens ?? NaN,\n      },\n      finishReason: mapOpenAICompatibleFinishReason(choice.finish_reason),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      response: getResponseMetadata(response),\n      warnings,\n      request: { body: JSON.stringify(args) },\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV1['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV1['doStream']>>> {\n    const { args, warnings } = this.getArgs(options);\n\n    const body = {\n      ...args,\n      stream: true,\n    };\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: this.failedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        this.chunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const { prompt: rawPrompt, ...rawSettings } = args;\n\n    let finishReason: LanguageModelV1FinishReason = 'unknown';\n    let usage: { promptTokens: number; completionTokens: number } = {\n      promptTokens: Number.NaN,\n      completionTokens: Number.NaN,\n    };\n    let isFirstChunk = true;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<z.infer<typeof this.chunkSchema>>,\n          LanguageModelV1StreamPart\n        >({\n          transform(chunk, controller) {\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            // handle error chunks:\n            if ('error' in value) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: value.error });\n              return;\n            }\n\n            if (isFirstChunk) {\n              isFirstChunk = false;\n\n              controller.enqueue({\n                type: 'response-metadata',\n                ...getResponseMetadata(value),\n              });\n            }\n\n            if (value.usage != null) {\n              usage = {\n                promptTokens: value.usage.prompt_tokens,\n                completionTokens: value.usage.completion_tokens,\n              };\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = mapOpenAICompatibleFinishReason(\n                choice.finish_reason,\n              );\n            }\n\n            if (choice?.text != null) {\n              controller.enqueue({\n                type: 'text-delta',\n                textDelta: choice.text,\n              });\n            }\n          },\n\n          flush(controller) {\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage,\n            });\n          },\n        }),\n      ),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      warnings,\n      request: { body: JSON.stringify(body) },\n    };\n  }\n}\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiCompatibleCompletionResponseSchema = z.object({\n  id: z.string().nullish(),\n  created: z.number().nullish(),\n  model: z.string().nullish(),\n  choices: z.array(\n    z.object({\n      text: z.string(),\n      finish_reason: z.string(),\n    }),\n  ),\n  usage: z\n    .object({\n      prompt_tokens: z.number(),\n      completion_tokens: z.number(),\n    })\n    .nullish(),\n});\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst createOpenAICompatibleCompletionChunkSchema = <\n  ERROR_SCHEMA extends z.ZodType,\n>(\n  errorSchema: ERROR_SCHEMA,\n) =>\n  z.union([\n    z.object({\n      id: z.string().nullish(),\n      created: z.number().nullish(),\n      model: z.string().nullish(),\n      choices: z.array(\n        z.object({\n          text: z.string(),\n          finish_reason: z.string().nullish(),\n          index: z.number(),\n        }),\n      ),\n      usage: z\n        .object({\n          prompt_tokens: z.number(),\n          completion_tokens: z.number(),\n        })\n        .nullish(),\n    }),\n    errorSchema,\n  ]);\n","import {\n  InvalidPromptError,\n  LanguageModelV1Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\n\nexport function convertToOpenAICompatibleCompletionPrompt({\n  prompt,\n  inputFormat,\n  user = 'user',\n  assistant = 'assistant',\n}: {\n  prompt: LanguageModelV1Prompt;\n  inputFormat: 'prompt' | 'messages';\n  user?: string;\n  assistant?: string;\n}): {\n  prompt: string;\n  stopSequences?: string[];\n} {\n  // When the user supplied a prompt input, we don't transform it:\n  if (\n    inputFormat === 'prompt' &&\n    prompt.length === 1 &&\n    prompt[0].role === 'user' &&\n    prompt[0].content.length === 1 &&\n    prompt[0].content[0].type === 'text'\n  ) {\n    return { prompt: prompt[0].content[0].text };\n  }\n\n  // otherwise transform to a chat message format:\n  let text = '';\n\n  // if first message is a system message, add it to the text:\n  if (prompt[0].role === 'system') {\n    text += `${prompt[0].content}\\n\\n`;\n    prompt = prompt.slice(1);\n  }\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        throw new InvalidPromptError({\n          message: 'Unexpected system message in prompt: ${content}',\n          prompt,\n        });\n      }\n\n      case 'user': {\n        const userMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n              case 'image': {\n                throw new UnsupportedFunctionalityError({\n                  functionality: 'images',\n                });\n              }\n            }\n          })\n          .join('');\n\n        text += `${user}:\\n${userMessage}\\n\\n`;\n        break;\n      }\n\n      case 'assistant': {\n        const assistantMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n              case 'tool-call': {\n                throw new UnsupportedFunctionalityError({\n                  functionality: 'tool-call messages',\n                });\n              }\n            }\n          })\n          .join('');\n\n        text += `${assistant}:\\n${assistantMessage}\\n\\n`;\n        break;\n      }\n\n      case 'tool': {\n        throw new UnsupportedFunctionalityError({\n          functionality: 'tool messages',\n        });\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  // Assistant message prefix:\n  text += `${assistant}:\\n`;\n\n  return {\n    prompt: text,\n    stopSequences: [`\\n${user}:`],\n  };\n}\n","import {\n  EmbeddingModelV1,\n  TooManyEmbeddingValuesForCallError,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonErrorResponseHandler,\n  createJsonResponseHandler,\n  FetchFunction,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\nimport {\n  OpenAICompatibleEmbeddingModelId,\n  OpenAICompatibleEmbeddingSettings,\n} from './openai-compatible-embedding-settings';\nimport {\n  defaultOpenAICompatibleErrorStructure,\n  ProviderErrorStructure,\n} from './openai-compatible-error';\n\ntype OpenAICompatibleEmbeddingConfig = {\n  /**\nOverride the maximum number of embeddings per call.\n   */\n  maxEmbeddingsPerCall?: number;\n\n  /**\nOverride the parallelism of embedding calls.\n  */\n  supportsParallelCalls?: boolean;\n\n  provider: string;\n  url: (options: { modelId: string; path: string }) => string;\n  headers: () => Record<string, string | undefined>;\n  fetch?: FetchFunction;\n  errorStructure?: ProviderErrorStructure<any>;\n};\n\nexport class OpenAICompatibleEmbeddingModel\n  implements EmbeddingModelV1<string>\n{\n  readonly specificationVersion = 'v1';\n  readonly modelId: OpenAICompatibleEmbeddingModelId;\n\n  private readonly config: OpenAICompatibleEmbeddingConfig;\n  private readonly settings: OpenAICompatibleEmbeddingSettings;\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  get maxEmbeddingsPerCall(): number {\n    return this.config.maxEmbeddingsPerCall ?? 2048;\n  }\n\n  get supportsParallelCalls(): boolean {\n    return this.config.supportsParallelCalls ?? true;\n  }\n\n  constructor(\n    modelId: OpenAICompatibleEmbeddingModelId,\n    settings: OpenAICompatibleEmbeddingSettings,\n    config: OpenAICompatibleEmbeddingConfig,\n  ) {\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n  }\n\n  async doEmbed({\n    values,\n    headers,\n    abortSignal,\n  }: Parameters<EmbeddingModelV1<string>['doEmbed']>[0]): Promise<\n    Awaited<ReturnType<EmbeddingModelV1<string>['doEmbed']>>\n  > {\n    if (values.length > this.maxEmbeddingsPerCall) {\n      throw new TooManyEmbeddingValuesForCallError({\n        provider: this.provider,\n        modelId: this.modelId,\n        maxEmbeddingsPerCall: this.maxEmbeddingsPerCall,\n        values,\n      });\n    }\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/embeddings',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        input: values,\n        encoding_format: 'float',\n        dimensions: this.settings.dimensions,\n        user: this.settings.user,\n      },\n      failedResponseHandler: createJsonErrorResponseHandler(\n        this.config.errorStructure ?? defaultOpenAICompatibleErrorStructure,\n      ),\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiTextEmbeddingResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      embeddings: response.data.map(item => item.embedding),\n      usage: response.usage\n        ? { tokens: response.usage.prompt_tokens }\n        : undefined,\n      rawResponse: { headers: responseHeaders },\n    };\n  }\n}\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiTextEmbeddingResponseSchema = z.object({\n  data: z.array(z.object({ embedding: z.array(z.number()) })),\n  usage: z.object({ prompt_tokens: z.number() }).nullish(),\n});\n","import {\n  EmbeddingModelV1,\n  LanguageModelV1,\n  ProviderV1,\n} from '@ai-sdk/provider';\nimport { FetchFunction, withoutTrailingSlash } from '@ai-sdk/provider-utils';\nimport { OpenAICompatibleChatLanguageModel } from './openai-compatible-chat-language-model';\nimport { OpenAICompatibleChatSettings } from './openai-compatible-chat-settings';\nimport { OpenAICompatibleCompletionLanguageModel } from './openai-compatible-completion-language-model';\nimport { OpenAICompatibleCompletionSettings } from './openai-compatible-completion-settings';\nimport { OpenAICompatibleEmbeddingModel } from './openai-compatible-embedding-model';\nimport { OpenAICompatibleEmbeddingSettings } from './openai-compatible-embedding-settings';\n\nexport interface OpenAICompatibleProvider<\n  CHAT_MODEL_IDS extends string = string,\n  COMPLETION_MODEL_IDS extends string = string,\n  EMBEDDING_MODEL_IDS extends string = string,\n> extends ProviderV1 {\n  (\n    modelId: CHAT_MODEL_IDS,\n    settings?: OpenAICompatibleChatSettings,\n  ): LanguageModelV1;\n\n  languageModel(\n    modelId: CHAT_MODEL_IDS,\n    settings?: OpenAICompatibleChatSettings,\n  ): LanguageModelV1;\n\n  chatModel(\n    modelId: CHAT_MODEL_IDS,\n    settings?: OpenAICompatibleChatSettings,\n  ): LanguageModelV1;\n\n  completionModel(\n    modelId: COMPLETION_MODEL_IDS,\n    settings?: OpenAICompatibleCompletionSettings,\n  ): LanguageModelV1;\n\n  textEmbeddingModel(\n    modelId: EMBEDDING_MODEL_IDS,\n    settings?: OpenAICompatibleEmbeddingSettings,\n  ): EmbeddingModelV1<string>;\n}\n\nexport interface OpenAICompatibleProviderSettings {\n  /**\nBase URL for the API calls.\n   */\n  baseURL: string;\n\n  /**\nProvider name.\n   */\n  name: string;\n\n  /**\nAPI key for authenticating requests. If specified, adds an `Authorization`\nheader to request headers with the value `Bearer <apiKey>`. This will be added\nbefore any headers potentially specified in the `headers` option.\n   */\n  apiKey?: string;\n\n  /**\nOptional custom headers to include in requests. These will be added to request headers\nafter any headers potentially added by use of the `apiKey` option.\n   */\n  headers?: Record<string, string>;\n\n  /**\nOptional custom url query parameters to include in request urls.\n   */\n  queryParams?: Record<string, string>;\n\n  /**\nCustom fetch implementation. You can use it as a middleware to intercept requests,\nor to provide a custom fetch implementation for e.g. testing.\n   */\n  fetch?: FetchFunction;\n}\n\n/**\nCreate an OpenAICompatible provider instance.\n */\nexport function createOpenAICompatible<\n  CHAT_MODEL_IDS extends string,\n  COMPLETION_MODEL_IDS extends string,\n  EMBEDDING_MODEL_IDS extends string,\n>(\n  options: OpenAICompatibleProviderSettings,\n): OpenAICompatibleProvider<\n  CHAT_MODEL_IDS,\n  COMPLETION_MODEL_IDS,\n  EMBEDDING_MODEL_IDS\n> {\n  const baseURL = withoutTrailingSlash(options.baseURL);\n  const providerName = options.name;\n\n  interface CommonModelConfig {\n    provider: string;\n    url: ({ path }: { path: string }) => string;\n    headers: () => Record<string, string>;\n    fetch?: FetchFunction;\n  }\n\n  const getHeaders = () => ({\n    ...(options.apiKey && { Authorization: `Bearer ${options.apiKey}` }),\n    ...options.headers,\n  });\n\n  const getCommonModelConfig = (modelType: string): CommonModelConfig => ({\n    provider: `${providerName}.${modelType}`,\n    url: ({ path }) => {\n      const url = new URL(`${baseURL}${path}`);\n      if (options.queryParams) {\n        url.search = new URLSearchParams(options.queryParams).toString();\n      }\n      return url.toString();\n    },\n    headers: getHeaders,\n    fetch: options.fetch,\n  });\n\n  const createLanguageModel = (\n    modelId: CHAT_MODEL_IDS,\n    settings: OpenAICompatibleChatSettings = {},\n  ) => createChatModel(modelId, settings);\n\n  const createChatModel = (\n    modelId: CHAT_MODEL_IDS,\n    settings: OpenAICompatibleChatSettings = {},\n  ) =>\n    new OpenAICompatibleChatLanguageModel(modelId, settings, {\n      ...getCommonModelConfig('chat'),\n      defaultObjectGenerationMode: 'tool',\n    });\n\n  const createCompletionModel = (\n    modelId: COMPLETION_MODEL_IDS,\n    settings: OpenAICompatibleCompletionSettings = {},\n  ) =>\n    new OpenAICompatibleCompletionLanguageModel(\n      modelId,\n      settings,\n      getCommonModelConfig('completion'),\n    );\n\n  const createEmbeddingModel = (\n    modelId: EMBEDDING_MODEL_IDS,\n    settings: OpenAICompatibleEmbeddingSettings = {},\n  ) =>\n    new OpenAICompatibleEmbeddingModel(\n      modelId,\n      settings,\n      getCommonModelConfig('embedding'),\n    );\n\n  const provider = (\n    modelId: CHAT_MODEL_IDS,\n    settings?: OpenAICompatibleChatSettings,\n  ) => createLanguageModel(modelId, settings);\n\n  provider.languageModel = createLanguageModel;\n  provider.chatModel = createChatModel;\n  provider.completionModel = createCompletionModel;\n  provider.textEmbeddingModel = createEmbeddingModel;\n\n  return provider as OpenAICompatibleProvider<\n    CHAT_MODEL_IDS,\n    COMPLETION_MODEL_IDS,\n    EMBEDDING_MODEL_IDS\n  >;\n}\n"],"names":["z","UnsupportedFunctionalityError","_a","toolCall","z","UnsupportedFunctionalityError","combineHeaders","createEventSourceResponseHandler","createJsonErrorResponseHandler","createJsonResponseHandler","postJsonToApi","z","UnsupportedFunctionalityError","createJsonErrorResponseHandler","UnsupportedFunctionalityError","postJsonToApi","combineHeaders","createJsonResponseHandler","createEventSourceResponseHandler","z","combineHeaders","createJsonErrorResponseHandler","createJsonResponseHandler","postJsonToApi","z","postJsonToApi","combineHeaders","createJsonErrorResponseHandler","createJsonResponseHandler","z"],"mappings":";;;;;;;AAAA;AASA;AAYA,SAAS,KAAAA,UAAS;;;;;;ACblB,SAAS,kBAAkB,OAAA,EAExB;IAVH,IAAA,IAAA;IAWE,OAAA,CAAO,KAAA,CAAA,KAAA,WAAA,OAAA,KAAA,IAAA,QAAS,gBAAA,KAAT,OAAA,KAAA,IAAA,GAA2B,gBAAA,KAA3B,OAAA,KAA+C,CAAC;AACzD;AAEO,SAAS,sCACd,MAAA,EAC4B;IAC5B,MAAM,WAAuC,CAAC,CAAA;IAC9C,KAAA,MAAW,EAAE,IAAA,EAAM,OAAA,EAAS,GAAG,QAAQ,CAAA,IAAK,OAAQ;QAClD,MAAM,WAAW,kBAAkB;YAAE,GAAG,OAAA;QAAQ,CAAC;QACjD,OAAQ,MAAM;YACZ,KAAK;gBAAU;oBACb,SAAS,IAAA,CAAK;wBAAE,MAAM;wBAAU;wBAAS,GAAG,QAAA;oBAAS,CAAC;oBACtD;gBACF;YAEA,KAAK;gBAAQ;oBACX,IAAI,QAAQ,MAAA,KAAW,KAAK,OAAA,CAAQ,CAAC,CAAA,CAAE,IAAA,KAAS,QAAQ;wBACtD,SAAS,IAAA,CAAK;4BACZ,MAAM;4BACN,SAAS,OAAA,CAAQ,CAAC,CAAA,CAAE,IAAA;4BACpB,GAAG,kBAAkB,OAAA,CAAQ,CAAC,CAAC,CAAA;wBACjC,CAAC;wBACD;oBACF;oBAEA,SAAS,IAAA,CAAK;wBACZ,MAAM;wBACN,SAAS,QAAQ,GAAA,CAAI,CAAA,SAAQ;4BAtCvC,IAAA;4BAuCY,MAAM,eAAe,kBAAkB,IAAI;4BAC3C,OAAQ,KAAK,IAAA,EAAM;gCACjB,KAAK;oCAAQ;wCACX,OAAO;4CAAE,MAAM;4CAAQ,MAAM,KAAK,IAAA;4CAAM,GAAG,YAAA;wCAAa;oCAC1D;gCACA,KAAK;oCAAS;wCACZ,OAAO;4CACL,MAAM;4CACN,WAAW;gDACT,KACE,KAAK,KAAA,YAAiB,MAClB,KAAK,KAAA,CAAM,QAAA,CAAS,IACpB,CAAA,KAAA,EAAA,CACE,KAAA,KAAK,QAAA,KAAL,OAAA,KAAiB,YACnB,CAAA,QAAA,kNAAW,4BAAA,EAA0B,KAAK,KAAK,CAAC,EAAA;4CACxD;4CACA,GAAG,YAAA;wCACL;oCACF;gCACA,KAAK;oCAAQ;wCACX,MAAM,uMAAI,gCAAA,CAA8B;4CACtC,eAAe;wCACjB,CAAC;oCACH;4BACF;wBACF,CAAC;wBACD,GAAG,QAAA;oBACL,CAAC;oBAED;gBACF;YAEA,KAAK;gBAAa;oBAChB,IAAI,OAAO;oBACX,MAAM,YAID,CAAC,CAAA;oBAEN,KAAA,MAAW,QAAQ,QAAS;wBAC1B,MAAM,eAAe,kBAAkB,IAAI;wBAC3C,OAAQ,KAAK,IAAA,EAAM;4BACjB,KAAK;gCAAQ;oCACX,QAAQ,KAAK,IAAA;oCACb;gCACF;4BACA,KAAK;gCAAa;oCAChB,UAAU,IAAA,CAAK;wCACb,IAAI,KAAK,UAAA;wCACT,MAAM;wCACN,UAAU;4CACR,MAAM,KAAK,QAAA;4CACX,WAAW,KAAK,SAAA,CAAU,KAAK,IAAI;wCACrC;wCACA,GAAG,YAAA;oCACL,CAAC;oCACD;gCACF;4BACA;gCAAS;oCACP,MAAM,mBAA0B;oCAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;gCACzD;wBACF;oBACF;oBAEA,SAAS,IAAA,CAAK;wBACZ,MAAM;wBACN,SAAS;wBACT,YAAY,UAAU,MAAA,GAAS,IAAI,YAAY,KAAA;wBAC/C,GAAG,QAAA;oBACL,CAAC;oBAED;gBACF;YAEA,KAAK;gBAAQ;oBACX,KAAA,MAAW,gBAAgB,QAAS;wBAClC,MAAM,uBAAuB,kBAAkB,YAAY;wBAC3D,SAAS,IAAA,CAAK;4BACZ,MAAM;4BACN,cAAc,aAAa,UAAA;4BAC3B,SAAS,KAAK,SAAA,CAAU,aAAa,MAAM;4BAC3C,GAAG,oBAAA;wBACL,CAAC;oBACH;oBACA;gBACF;YAEA;gBAAS;oBACP,MAAM,mBAA0B;oBAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;gBACzD;QACF;IACF;IAEA,OAAO;AACT;;ACxIO,SAAS,oBAAoB,EAClC,EAAA,EACA,KAAA,EACA,OAAA,EACF,EAIG;IACD,OAAO;QACL,IAAI,MAAA,OAAA,KAAM,KAAA;QACV,SAAS,SAAA,OAAA,QAAS,KAAA;QAClB,WAAW,WAAW,OAAO,IAAI,KAAK,UAAU,GAAI,IAAI,KAAA;IAC1D;AACF;;ACZO,SAAS,gCACd,YAAA,EAC6B;IAC7B,OAAQ,cAAc;QACpB,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;QACL,KAAK;YACH,OAAO;QACT;YACE,OAAO;IACX;AACF;;AChBO,IAAM,0KAAkC,IAAA,CAAE,MAAA,CAAO;IACtD,+IAAO,IAAA,CAAE,MAAA,CAAO;QACd,iJAAS,IAAA,CAAE,MAAA,CAAO;QAAA,iEAAA;QAAA,iEAAA;QAAA,aAAA;QAKlB,MAAM,4IAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QACzB,+IAAO,IAAA,CAAE,GAAA,CAAI,EAAE,OAAA,CAAQ;QACvB,MAAM,4IAAA,CAAE,KAAA,CAAM;oJAAC,IAAA,CAAE,MAAA,CAAO;mJAAG,KAAA,CAAE,MAAA,CAAO,CAAC;SAAC,EAAE,OAAA,CAAQ;IAClD,CAAC;AACH,CAAC;AAYM,IAAM,wCACX;IACE,aAAa;IACb,gBAAgB,CAAA,OAAQ,KAAK,KAAA,CAAM,OAAA;AACrC;;ACvBK,SAAS,aAAa,EAC3B,IAAA,EACA,iBAAA,EACF,EAuBE;IAhCF,IAAA;IAkCE,MAAM,QAAA,CAAA,CAAQ,KAAA,KAAK,KAAA,KAAL,OAAA,KAAA,IAAA,GAAY,MAAA,IAAS,KAAK,KAAA,GAAQ,KAAA;IAChD,MAAM,eAA6C,CAAC,CAAA;IAEpD,IAAI,SAAS,MAAM;QACjB,OAAO;YAAE,OAAO,KAAA;YAAW,aAAa,KAAA;YAAW;QAAa;IAClE;IAEA,MAAM,aAAa,KAAK,UAAA;IAExB,MAAM,oBAOD,CAAC,CAAA;IAEN,KAAA,MAAW,QAAQ,MAAO;QACxB,IAAI,KAAK,IAAA,KAAS,oBAAoB;YACpC,aAAa,IAAA,CAAK;gBAAE,MAAM;gBAAoB;YAAK,CAAC;QACtD,OAAO;YACL,kBAAkB,IAAA,CAAK;gBACrB,MAAM;gBACN,UAAU;oBACR,MAAM,KAAK,IAAA;oBACX,aAAa,KAAK,WAAA;oBAClB,YAAY,KAAK,UAAA;gBACnB;YACF,CAAC;QACH;IACF;IAEA,IAAI,cAAc,MAAM;QACtB,OAAO;YAAE,OAAO;YAAmB,aAAa,KAAA;YAAW;QAAa;IAC1E;IAEA,MAAM,OAAO,WAAW,IAAA;IAExB,OAAQ,MAAM;QACZ,KAAK;QACL,KAAK;QACL,KAAK;YACH,OAAO;gBAAE,OAAO;gBAAmB,aAAa;gBAAM;YAAa;QACrE,KAAK;YACH,OAAO;gBACL,OAAO;gBACP,aAAa;oBACX,MAAM;oBACN,UAAU;wBACR,MAAM,WAAW,QAAA;oBACnB;gBACF;gBACA;YACF;QACF;YAAS;gBACP,MAAM,mBAA0B;gBAChC,MAAM,IAAIC,mOAAAA,CAA8B;oBACtC,eAAe,CAAA,8BAAA,EAAiC,gBAAgB,EAAA;gBAClE,CAAC;YACH;IACF;AACF;;ALvCO,IAAM,oCAAN,MAAmE;IAAA,gCAAA;IAYxE,YACE,OAAA,EACA,QAAA,EACA,MAAA,CACA;QAfF,IAAA,CAAS,oBAAA,GAAuB;QA1DlC,IAAA,IAAA;QA0EI,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,MAAA,GAAS;QAGd,MAAM,iBAAA,CACJ,KAAA,OAAO,cAAA,KAAP,OAAA,KAAyB;QAC3B,IAAA,CAAK,WAAA,GAAc,sCACjB,eAAe,WAAA;QAEjB,IAAA,CAAK,qBAAA,mNAAwB,iCAAA,EAA+B,cAAc;QAE1E,IAAA,CAAK,yBAAA,GAAA,CAA4B,KAAA,OAAO,yBAAA,KAAP,OAAA,KAAoC;IACvE;IAEA,IAAI,8BAA2D;QAC7D,OAAO,IAAA,CAAK,MAAA,CAAO,2BAAA;IACrB;IAEA,IAAI,WAAmB;QACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA;IACrB;IAEA,IAAY,sBAA8B;QACxC,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA,CAAS,KAAA,CAAM,GAAG,CAAA,CAAE,CAAC,CAAA,CAAE,IAAA,CAAK;IACjD;IAEQ,QAAQ,EACd,IAAA,EACA,MAAA,EACA,SAAA,EACA,WAAA,EACA,IAAA,EACA,IAAA,EACA,gBAAA,EACA,eAAA,EACA,gBAAA,EACA,aAAA,EACA,cAAA,EACA,IAAA,EACF,EAAiD;QAlHnD,IAAA,IAAA;QAmHI,MAAM,OAAO,KAAK,IAAA;QAElB,MAAM,WAAyC,CAAC,CAAA;QAEhD,IAAI,QAAQ,MAAM;YAChB,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;YACX,CAAC;QACH;QAEA,IAAA,CACE,kBAAA,OAAA,KAAA,IAAA,eAAgB,IAAA,MAAS,UACzB,eAAe,MAAA,IAAU,QACzB,CAAC,IAAA,CAAK,yBAAA,EACN;YACA,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;gBACT,SACE;YACJ,CAAC;QACH;QAEA,MAAM,WAAW;YAAA,YAAA;YAEf,OAAO,IAAA,CAAK,OAAA;YAAA,2BAAA;YAGZ,MAAM,IAAA,CAAK,QAAA,CAAS,IAAA;YAAA,yBAAA;YAGpB,YAAY;YACZ;YACA,OAAO;YACP,mBAAmB;YACnB,kBAAkB;YAClB,iBAAA,CACE,kBAAA,OAAA,KAAA,IAAA,eAAgB,IAAA,MAAS,SACrB,IAAA,CAAK,yBAAA,KAA8B,QACnC,eAAe,MAAA,IAAU,OACvB;gBACE,MAAM;gBACN,aAAa;oBACX,QAAQ,eAAe,MAAA;oBACvB,MAAA,CAAM,KAAA,eAAe,IAAA,KAAf,OAAA,KAAuB;oBAC7B,aAAa,eAAe,WAAA;gBAC9B;YACF,IACA;gBAAE,MAAM;YAAc,IACxB,KAAA;YAEN,MAAM;YACN;YACA,GAAG,oBAAA,OAAA,KAAA,IAAA,gBAAA,CAAmB,IAAA,CAAK,mBAAA,CAAA;YAAA,YAAA;YAG3B,UAAU,sCAAsC,MAAM;QACxD;QAEA,OAAQ,MAAM;YACZ,KAAK;gBAAW;oBACd,MAAM,EAAE,KAAA,EAAO,WAAA,EAAa,YAAA,CAAa,CAAA,GAAI,aAAa;wBACxD;wBACA,mBAAmB,IAAA,CAAK,yBAAA;oBAC1B,CAAC;oBAED,OAAO;wBACL,MAAM;4BAAE,GAAG,QAAA;4BAAU;4BAAO;wBAAY;wBACxC,UAAU,CAAC;+BAAG,UAAU;+BAAG,YAAY;yBAAA;oBACzC;gBACF;YAEA,KAAK;gBAAe;oBAClB,OAAO;wBACL,MAAM;4BACJ,GAAG,QAAA;4BACH,iBACE,IAAA,CAAK,yBAAA,KAA8B,QAAQ,KAAK,MAAA,IAAU,OACtD;gCACE,MAAM;gCACN,aAAa;oCACX,QAAQ,KAAK,MAAA;oCACb,MAAA,CAAM,KAAA,KAAK,IAAA,KAAL,OAAA,KAAa;oCACnB,aAAa,KAAK,WAAA;gCACpB;4BACF,IACA;gCAAE,MAAM;4BAAc;wBAC9B;wBACA;oBACF;gBACF;YAEA,KAAK;gBAAe;oBAClB,OAAO;wBACL,MAAM;4BACJ,GAAG,QAAA;4BACH,aAAa;gCACX,MAAM;gCACN,UAAU;oCAAE,MAAM,KAAK,IAAA,CAAK,IAAA;gCAAK;4BACnC;4BACA,OAAO;gCACL;oCACE,MAAM;oCACN,UAAU;wCACR,MAAM,KAAK,IAAA,CAAK,IAAA;wCAChB,aAAa,KAAK,IAAA,CAAK,WAAA;wCACvB,YAAY,KAAK,IAAA,CAAK,UAAA;oCACxB;gCACF;6BACF;wBACF;wBACA;oBACF;gBACF;YAEA;gBAAS;oBACP,MAAM,mBAA0B;oBAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;gBACzD;QACF;IACF;IAEA,MAAM,WACJ,OAAA,EAC6D;QAhPjE,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;QAiPI,MAAM,EAAE,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,IAAA,CAAK,OAAA,CAAQ;YAAE,GAAG,OAAA;QAAQ,CAAC;QAEtD,MAAM,OAAO,KAAK,SAAA,CAAU,IAAI;QAEhC,MAAM,EACJ,eAAA,EACA,OAAO,YAAA,EACP,UAAU,UAAA,EACZ,GAAI,sNAAM,gBAAA,EAAc;YACtB,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,SAAS,iOAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D,MAAM;YACN,uBAAuB,IAAA,CAAK,qBAAA;YAC5B,2BAA2B,4OAAA,EACzB;YAEF,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,MAAM,EAAE,UAAU,SAAA,EAAW,GAAG,YAAY,CAAA,GAAI;QAChD,MAAM,SAAS,aAAa,OAAA,CAAQ,CAAC,CAAA;QACrC,MAAM,mBAAA,CAAmB,KAAA,CAAA,KAAA,IAAA,CAAK,MAAA,CAAO,iBAAA,KAAZ,OAAA,KAAA,IAAA,GAA+B,eAAA,KAA/B,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,IAAiD;YACxE;QACF;QAEA,OAAO;YACL,MAAA,CAAM,KAAA,OAAO,OAAA,CAAQ,OAAA,KAAf,OAAA,KAA0B,KAAA;YAChC,WAAA,CAAW,KAAA,OAAO,OAAA,CAAQ,iBAAA,KAAf,OAAA,KAAoC,KAAA;YAC/C,WAAA,CAAW,KAAA,OAAO,OAAA,CAAQ,UAAA,KAAf,OAAA,KAAA,IAAA,GAA2B,GAAA,CAAI,CAAA,aAAS;gBAjRzD,IAAAC;gBAiR6D,OAAA;oBACrD,cAAc;oBACd,YAAA,CAAYA,MAAA,SAAS,EAAA,KAAT,OAAAA,sNAAe,aAAA,CAAW;oBACtC,UAAU,SAAS,QAAA,CAAS,IAAA;oBAC5B,MAAM,SAAS,QAAA,CAAS,SAAA;gBAC1B;YAAA;YACA,cAAc,gCAAgC,OAAO,aAAa;YAClE,OAAO;gBACL,cAAA,CAAc,KAAA,CAAA,KAAA,aAAa,KAAA,KAAb,OAAA,KAAA,IAAA,GAAoB,aAAA,KAApB,OAAA,KAAqC;gBACnD,kBAAA,CAAkB,KAAA,CAAA,KAAA,aAAa,KAAA,KAAb,OAAA,KAAA,IAAA,GAAoB,iBAAA,KAApB,OAAA,KAAyC;YAC7D;YACA,GAAI,oBAAoB;gBAAE;YAAiB,CAAA;YAC3C,SAAS;gBAAE;gBAAW;YAAY;YAClC,aAAa;gBAAE,SAAS;YAAgB;YACxC,UAAU,oBAAoB,YAAY;YAC1C;YACA,SAAS;gBAAE;YAAK;QAClB;IACF;IAEA,MAAM,SACJ,OAAA,EAC2D;QAvS/D,IAAA;QAwSI,IAAI,IAAA,CAAK,QAAA,CAAS,iBAAA,EAAmB;YACnC,MAAM,SAAS,MAAM,IAAA,CAAK,UAAA,CAAW,OAAO;YAC5C,MAAM,kBAAkB,IAAI,eAA0C;gBACpE,OAAM,UAAA,EAAY;oBAChB,WAAW,OAAA,CAAQ;wBAAE,MAAM;wBAAqB,GAAG,OAAO,QAAA;oBAAS,CAAC;oBACpE,IAAI,OAAO,SAAA,EAAW;wBACpB,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,WAAW,OAAO,SAAA;wBACpB,CAAC;oBACH;oBACA,IAAI,OAAO,IAAA,EAAM;wBACf,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,WAAW,OAAO,IAAA;wBACpB,CAAC;oBACH;oBACA,IAAI,OAAO,SAAA,EAAW;wBACpB,KAAA,MAAW,YAAY,OAAO,SAAA,CAAW;4BACvC,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,GAAG,QAAA;4BACL,CAAC;wBACH;oBACF;oBACA,WAAW,OAAA,CAAQ;wBACjB,MAAM;wBACN,cAAc,OAAO,YAAA;wBACrB,OAAO,OAAO,KAAA;wBACd,UAAU,OAAO,QAAA;wBACjB,kBAAkB,OAAO,gBAAA;oBAC3B,CAAC;oBACD,WAAW,KAAA,CAAM;gBACnB;YACF,CAAC;YACD,OAAO;gBACL,QAAQ;gBACR,SAAS,OAAO,OAAA;gBAChB,aAAa,OAAO,WAAA;gBACpB,UAAU,OAAO,QAAA;YACnB;QACF;QAEA,MAAM,EAAE,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,IAAA,CAAK,OAAA,CAAQ;YAAE,GAAG,OAAA;QAAQ,CAAC;QAEtD,MAAM,OAAO,KAAK,SAAA,CAAU;YAAE,GAAG,IAAA;YAAM,QAAQ;QAAK,CAAC;QACrD,MAAM,oBAAA,CACJ,KAAA,IAAA,CAAK,MAAA,CAAO,iBAAA,KAAZ,OAAA,KAAA,IAAA,GAA+B,qBAAA;QAEjC,MAAM,EAAE,eAAA,EAAiB,OAAO,QAAA,CAAS,CAAA,GAAI,sNAAM,gBAAA,EAAc;YAC/D,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,yNAAS,iBAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D,MAAM;gBACJ,GAAG,IAAA;gBACH,QAAQ;YACV;YACA,uBAAuB,IAAA,CAAK,qBAAA;YAC5B,2OAA2B,mCAAA,EACzB,IAAA,CAAK,WAAA;YAEP,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,MAAM,EAAE,UAAU,SAAA,EAAW,GAAG,YAAY,CAAA,GAAI;QAEhD,MAAM,YAQD,CAAC,CAAA;QAEN,IAAI,eAA4C;QAChD,IAAI,QAGA;YACF,cAAc,KAAA;YACd,kBAAkB,KAAA;QACpB;QACA,IAAI,eAAe;QAEnB,OAAO;YACL,QAAQ,SAAS,WAAA,CACf,IAAI,gBAGF;gBAAA,mFAAA;gBAEA,WAAU,KAAA,EAAO,UAAA,EAAY;oBAxYvC,IAAAA,KAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;oBA0YY,IAAI,CAAC,MAAM,OAAA,EAAS;wBAClB,eAAe;wBACf,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO,MAAM,KAAA;wBAAM,CAAC;wBACxD;oBACF;oBACA,MAAM,QAAQ,MAAM,KAAA;oBAEpB,qBAAA,OAAA,KAAA,IAAA,kBAAmB,YAAA,CAAa,MAAM,QAAA;oBAGtC,IAAI,WAAW,OAAO;wBACpB,eAAe;wBACf,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO,MAAM,KAAA,CAAM,OAAA;wBAAQ,CAAC;wBAChE;oBACF;oBAEA,IAAI,cAAc;wBAChB,eAAe;wBAEf,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,GAAG,oBAAoB,KAAK,CAAA;wBAC9B,CAAC;oBACH;oBAEA,IAAI,MAAM,KAAA,IAAS,MAAM;wBACvB,QAAQ;4BACN,cAAA,CAAcA,MAAA,MAAM,KAAA,CAAM,aAAA,KAAZ,OAAAA,MAA6B,KAAA;4BAC3C,kBAAA,CAAkB,KAAA,MAAM,KAAA,CAAM,iBAAA,KAAZ,OAAA,KAAiC,KAAA;wBACrD;oBACF;oBAEA,MAAM,SAAS,MAAM,OAAA,CAAQ,CAAC,CAAA;oBAE9B,IAAA,CAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,aAAA,KAAiB,MAAM;wBACjC,eAAe,gCACb,OAAO,aAAA;oBAEX;oBAEA,IAAA,CAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,KAAA,KAAS,MAAM;wBACzB;oBACF;oBAEA,MAAM,QAAQ,OAAO,KAAA;oBAGrB,IAAI,MAAM,iBAAA,IAAqB,MAAM;wBACnC,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,WAAW,MAAM,iBAAA;wBACnB,CAAC;oBACH;oBAEA,IAAI,MAAM,OAAA,IAAW,MAAM;wBACzB,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,WAAW,MAAM,OAAA;wBACnB,CAAC;oBACH;oBAEA,IAAI,MAAM,UAAA,IAAc,MAAM;wBAC5B,KAAA,MAAW,iBAAiB,MAAM,UAAA,CAAY;4BAC5C,MAAM,QAAQ,cAAc,KAAA;4BAE5B,IAAI,SAAA,CAAU,KAAK,CAAA,IAAK,MAAM;gCAC5B,IAAI,cAAc,IAAA,KAAS,YAAY;oCACrC,MAAM,uMAAI,2BAAA,CAAyB;wCACjC,MAAM;wCACN,SAAS,CAAA,yBAAA,CAAA;oCACX,CAAC;gCACH;gCAEA,IAAI,cAAc,EAAA,IAAM,MAAM;oCAC5B,MAAM,uMAAI,2BAAA,CAAyB;wCACjC,MAAM;wCACN,SAAS,CAAA,6BAAA,CAAA;oCACX,CAAC;gCACH;gCAEA,IAAA,CAAA,CAAI,KAAA,cAAc,QAAA,KAAd,OAAA,KAAA,IAAA,GAAwB,IAAA,KAAQ,MAAM;oCACxC,MAAM,uMAAI,2BAAA,CAAyB;wCACjC,MAAM;wCACN,SAAS,CAAA,wCAAA,CAAA;oCACX,CAAC;gCACH;gCAEA,SAAA,CAAU,KAAK,CAAA,GAAI;oCACjB,IAAI,cAAc,EAAA;oCAClB,MAAM;oCACN,UAAU;wCACR,MAAM,cAAc,QAAA,CAAS,IAAA;wCAC7B,WAAA,CAAW,KAAA,cAAc,QAAA,CAAS,SAAA,KAAvB,OAAA,KAAoC;oCACjD;oCACA,aAAa;gCACf;gCAEA,MAAMC,YAAW,SAAA,CAAU,KAAK,CAAA;gCAEhC,IAAA,CAAA,CACE,KAAAA,UAAS,QAAA,KAAT,OAAA,KAAA,IAAA,GAAmB,IAAA,KAAQ,QAAA,CAAA,CAC3B,KAAAA,UAAS,QAAA,KAAT,OAAA,KAAA,IAAA,GAAmB,SAAA,KAAa,MAChC;oCAEA,IAAIA,UAAS,QAAA,CAAS,SAAA,CAAU,MAAA,GAAS,GAAG;wCAC1C,WAAW,OAAA,CAAQ;4CACjB,MAAM;4CACN,cAAc;4CACd,YAAYA,UAAS,EAAA;4CACrB,UAAUA,UAAS,QAAA,CAAS,IAAA;4CAC5B,eAAeA,UAAS,QAAA,CAAS,SAAA;wCACnC,CAAC;oCACH;oCAIA,IAAI,iOAAA,EAAeA,UAAS,QAAA,CAAS,SAAS,GAAG;wCAC/C,WAAW,OAAA,CAAQ;4CACjB,MAAM;4CACN,cAAc;4CACd,YAAA,CAAY,KAAAA,UAAS,EAAA,KAAT,OAAA,MAAe,4NAAA,CAAW;4CACtC,UAAUA,UAAS,QAAA,CAAS,IAAA;4CAC5B,MAAMA,UAAS,QAAA,CAAS,SAAA;wCAC1B,CAAC;wCACDA,UAAS,WAAA,GAAc;oCACzB;gCACF;gCAEA;4BACF;4BAGA,MAAM,WAAW,SAAA,CAAU,KAAK,CAAA;4BAEhC,IAAI,SAAS,WAAA,EAAa;gCACxB;4BACF;4BAEA,IAAA,CAAA,CAAI,KAAA,cAAc,QAAA,KAAd,OAAA,KAAA,IAAA,GAAwB,SAAA,KAAa,MAAM;gCAC7C,SAAS,QAAA,CAAU,SAAA,IAAA,CACjB,KAAA,CAAA,KAAA,cAAc,QAAA,KAAd,OAAA,KAAA,IAAA,GAAwB,SAAA,KAAxB,OAAA,KAAqC;4BACzC;4BAGA,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,cAAc;gCACd,YAAY,SAAS,EAAA;gCACrB,UAAU,SAAS,QAAA,CAAS,IAAA;gCAC5B,eAAA,CAAe,KAAA,cAAc,QAAA,CAAS,SAAA,KAAvB,OAAA,KAAoC;4BACrD,CAAC;4BAGD,IAAA,CAAA,CACE,KAAA,SAAS,QAAA,KAAT,OAAA,KAAA,IAAA,GAAmB,IAAA,KAAQ,QAAA,CAAA,CAC3B,KAAA,SAAS,QAAA,KAAT,OAAA,KAAA,IAAA,GAAmB,SAAA,KAAa,wNAChC,iBAAA,EAAe,SAAS,QAAA,CAAS,SAAS,GAC1C;gCACA,WAAW,OAAA,CAAQ;oCACjB,MAAM;oCACN,cAAc;oCACd,YAAA,CAAY,KAAA,SAAS,EAAA,KAAT,OAAA,oNAAe,cAAA,CAAW;oCACtC,UAAU,SAAS,QAAA,CAAS,IAAA;oCAC5B,MAAM,SAAS,QAAA,CAAS,SAAA;gCAC1B,CAAC;gCACD,SAAS,WAAA,GAAc;4BACzB;wBACF;oBACF;gBACF;gBAEA,OAAM,UAAA,EAAY;oBArjB5B,IAAAD,KAAA;oBAsjBY,MAAM,WAAW,qBAAA,OAAA,KAAA,IAAA,kBAAmB,aAAA;oBACpC,WAAW,OAAA,CAAQ;wBACjB,MAAM;wBACN;wBACA,OAAO;4BACL,cAAA,CAAcA,MAAA,MAAM,YAAA,KAAN,OAAAA,MAAsB;4BACpC,kBAAA,CAAkB,KAAA,MAAM,gBAAA,KAAN,OAAA,KAA0B;wBAC9C;wBACA,GAAI,YAAY;4BAAE,kBAAkB;wBAAS,CAAA;oBAC/C,CAAC;gBACH;YACF,CAAC;YAEH,SAAS;gBAAE;gBAAW;YAAY;YAClC,aAAa;gBAAE,SAAS;YAAgB;YACxC;YACA,SAAS;gBAAE;YAAK;QAClB;IACF;AACF;AAIA,IAAM,6KAAqCE,IAAAA,CAAE,MAAA,CAAO;IAClD,IAAIA,4IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACvB,iJAASA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC5B,OAAOA,4IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC1B,iJAASA,IAAAA,CAAE,KAAA,yIACTA,IAAAA,CAAE,MAAA,CAAO;QACP,iJAASA,IAAAA,CAAE,MAAA,CAAO;YAChB,8IAAMA,IAAAA,CAAE,OAAA,CAAQ,WAAW,EAAE,OAAA,CAAQ;YACrC,iJAASA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC5B,2JAAmBA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YACtC,oJAAYA,IAAAA,CACT,KAAA,yIACCA,IAAAA,CAAE,MAAA,CAAO;gBACP,4IAAIA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;gBACvB,MAAMA,4IAAAA,CAAE,OAAA,CAAQ,UAAU;gBAC1B,kJAAUA,IAAAA,CAAE,MAAA,CAAO;oBACjB,8IAAMA,IAAAA,CAAE,MAAA,CAAO;oBACf,mJAAWA,IAAAA,CAAE,MAAA,CAAO;gBACtB,CAAC;YACH,CAAC,GAEF,OAAA,CAAQ;QACb,CAAC;QACD,uJAAeA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACpC,CAAC;IAEH,+IAAOA,IAAAA,CACJ,MAAA,CAAO;QACN,eAAeA,4IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QAClC,2JAAmBA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACxC,CAAC,EACA,OAAA,CAAQ;AACb,CAAC;AAID,IAAM,wCAAwC,CAC5C,cAEAA,4IAAAA,CAAE,KAAA,CAAM;gJACNA,IAAAA,CAAE,MAAA,CAAO;YACP,4IAAIA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YACvB,iJAASA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC5B,+IAAOA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC1B,iJAASA,IAAAA,CAAE,KAAA,wIACTA,KAAAA,CAAE,MAAA,CAAO;gBACP,+IAAOA,IAAAA,CACJ,MAAA,CAAO;oBACN,8IAAMA,IAAAA,CAAE,IAAA,CAAK;wBAAC,WAAW;qBAAC,EAAE,OAAA,CAAQ;oBACpC,iJAASA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;oBAC5B,2JAAmBA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;oBACtC,oJAAYA,IAAAA,CACT,KAAA,CACCA,4IAAAA,CAAE,MAAA,CAAO;wBACP,+IAAOA,IAAAA,CAAE,MAAA,CAAO;wBAChB,4IAAIA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;wBACvB,8IAAMA,IAAAA,CAAE,OAAA,CAAQ,UAAU,EAAE,QAAA,CAAS;wBACrC,kJAAUA,IAAAA,CAAE,MAAA,CAAO;4BACjB,8IAAMA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;4BACzB,WAAWA,4IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;wBAChC,CAAC;oBACH,CAAC,GAEF,OAAA,CAAQ;gBACb,CAAC,EACA,OAAA,CAAQ;gBACX,uJAAeA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YACpC,CAAC;YAEH,+IAAOA,IAAAA,CACJ,MAAA,CAAO;gBACN,uJAAeA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;gBAClC,2JAAmBA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YACxC,CAAC,EACA,OAAA,CAAQ;QACb,CAAC;QACD;KACD;;;;;AOppBI,SAAS,0CAA0C,EACxD,MAAA,EACA,WAAA,EACA,OAAO,MAAA,EACP,YAAY,WAAA,EACd,EAQE;IAEA,IACE,gBAAgB,YAChB,OAAO,MAAA,KAAW,KAClB,MAAA,CAAO,CAAC,CAAA,CAAE,IAAA,KAAS,UACnB,MAAA,CAAO,CAAC,CAAA,CAAE,OAAA,CAAQ,MAAA,KAAW,KAC7B,MAAA,CAAO,CAAC,CAAA,CAAE,OAAA,CAAQ,CAAC,CAAA,CAAE,IAAA,KAAS,QAC9B;QACA,OAAO;YAAE,QAAQ,MAAA,CAAO,CAAC,CAAA,CAAE,OAAA,CAAQ,CAAC,CAAA,CAAE,IAAA;QAAK;IAC7C;IAGA,IAAI,OAAO;IAGX,IAAI,MAAA,CAAO,CAAC,CAAA,CAAE,IAAA,KAAS,UAAU;QAC/B,QAAQ,GAAG,MAAA,CAAO,CAAC,CAAA,CAAE,OAAO,CAAA;;AAAA,CAAA;QAC5B,SAAS,OAAO,KAAA,CAAM,CAAC;IACzB;IAEA,KAAA,MAAW,EAAE,IAAA,EAAM,OAAA,CAAQ,CAAA,IAAK,OAAQ;QACtC,OAAQ,MAAM;YACZ,KAAK;gBAAU;oBACb,MAAM,uMAAI,qBAAA,CAAmB;wBAC3B,SAAS;wBACT;oBACF,CAAC;gBACH;YAEA,KAAK;gBAAQ;oBACX,MAAM,cAAc,QACjB,GAAA,CAAI,CAAA,SAAQ;wBACX,OAAQ,KAAK,IAAA,EAAM;4BACjB,KAAK;gCAAQ;oCACX,OAAO,KAAK,IAAA;gCACd;4BACA,KAAK;gCAAS;oCACZ,MAAM,uMAAIQ,gCAAAA,CAA8B;wCACtC,eAAe;oCACjB,CAAC;gCACH;wBACF;oBACF,CAAC,EACA,IAAA,CAAK,EAAE;oBAEV,QAAQ,GAAG,IAAI,CAAA;AAAA,EAAM,WAAW,CAAA;;AAAA,CAAA;oBAChC;gBACF;YAEA,KAAK;gBAAa;oBAChB,MAAM,mBAAmB,QACtB,GAAA,CAAI,CAAA,SAAQ;wBACX,OAAQ,KAAK,IAAA,EAAM;4BACjB,KAAK;gCAAQ;oCACX,OAAO,KAAK,IAAA;gCACd;4BACA,KAAK;gCAAa;oCAChB,MAAM,IAAIA,mOAAAA,CAA8B;wCACtC,eAAe;oCACjB,CAAC;gCACH;wBACF;oBACF,CAAC,EACA,IAAA,CAAK,EAAE;oBAEV,QAAQ,GAAG,SAAS,CAAA;AAAA,EAAM,gBAAgB,CAAA;;AAAA,CAAA;oBAC1C;gBACF;YAEA,KAAK;gBAAQ;oBACX,MAAM,sMAAIA,iCAAAA,CAA8B;wBACtC,eAAe;oBACjB,CAAC;gBACH;YAEA;gBAAS;oBACP,MAAM,mBAA0B;oBAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;gBACzD;QACF;IACF;IAGA,QAAQ,GAAG,SAAS,CAAA;AAAA,CAAA;IAEpB,OAAO;QACL,QAAQ;QACR,eAAe;YAAC,CAAA;AAAA,EAAK,IAAI,CAAA,CAAA,CAAG;SAAA;IAC9B;AACF;;ADtEO,IAAM,0CAAN,MAEP;IAAA,gCAAA;IAWE,YACE,OAAA,EACA,QAAA,EACA,MAAA,CACA;QAdF,IAAA,CAAS,oBAAA,GAAuB;QAChC,IAAA,CAAS,2BAAA,GAA8B,KAAA;QA3CzC,IAAA;QAyDI,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,MAAA,GAAS;QAGd,MAAM,iBAAA,CACJ,KAAA,OAAO,cAAA,KAAP,OAAA,KAAyB;QAC3B,IAAA,CAAK,WAAA,GAAc,4CACjB,eAAe,WAAA;QAEjB,IAAA,CAAK,qBAAA,mNAAwBC,iCAAAA,EAA+B,cAAc;IAC5E;IAEA,IAAI,WAAmB;QACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA;IACrB;IAEA,IAAY,sBAA8B;QACxC,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA,CAAS,KAAA,CAAM,GAAG,CAAA,CAAE,CAAC,CAAA,CAAE,IAAA,CAAK;IACjD;IAEQ,QAAQ,EACd,IAAA,EACA,WAAA,EACA,MAAA,EACA,SAAA,EACA,WAAA,EACA,IAAA,EACA,IAAA,EACA,gBAAA,EACA,eAAA,EACA,eAAe,iBAAA,EACf,cAAA,EACA,IAAA,EACA,gBAAA,EACF,EAAiD;QA5FnD,IAAA;QA6FI,MAAM,OAAO,KAAK,IAAA;QAElB,MAAM,WAAyC,CAAC,CAAA;QAEhD,IAAI,QAAQ,MAAM;YAChB,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;YACX,CAAC;QACH;QAEA,IAAI,kBAAkB,QAAQ,eAAe,IAAA,KAAS,QAAQ;YAC5D,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;gBACT,SAAS;YACX,CAAC;QACH;QAEA,MAAM,EAAE,QAAQ,gBAAA,EAAkB,aAAA,CAAc,CAAA,GAC9C,0CAA0C;YAAE;YAAQ;QAAY,CAAC;QAEnE,MAAM,OAAO,CAAC;eAAI,iBAAA,OAAA,gBAAiB,CAAC,CAAA,EAAI;eAAI,qBAAA,OAAA,oBAAqB,CAAC,CAAE;SAAA;QAEpE,MAAM,WAAW;YAAA,YAAA;YAEf,OAAO,IAAA,CAAK,OAAA;YAAA,2BAAA;YAGZ,MAAM,IAAA,CAAK,QAAA,CAAS,IAAA;YACpB,YAAY,IAAA,CAAK,QAAA,CAAS,SAAA;YAC1B,QAAQ,IAAA,CAAK,QAAA,CAAS,MAAA;YACtB,MAAM,IAAA,CAAK,QAAA,CAAS,IAAA;YAAA,yBAAA;YAGpB,YAAY;YACZ;YACA,OAAO;YACP,mBAAmB;YACnB,kBAAkB;YAClB;YACA,GAAG,oBAAA,OAAA,KAAA,IAAA,gBAAA,CAAmB,IAAA,CAAK,mBAAA,CAAA;YAAA,UAAA;YAG3B,QAAQ;YAAA,kBAAA;YAGR,MAAM,KAAK,MAAA,GAAS,IAAI,OAAO,KAAA;QACjC;QAEA,OAAQ,MAAM;YACZ,KAAK;gBAAW;oBACd,IAAA,CAAI,KAAA,KAAK,KAAA,KAAL,OAAA,KAAA,IAAA,GAAY,MAAA,EAAQ;wBACtB,MAAM,uMAAIC,gCAAAA,CAA8B;4BACtC,eAAe;wBACjB,CAAC;oBACH;oBAEA,IAAI,KAAK,UAAA,EAAY;wBACnB,MAAM,sMAAIA,iCAAAA,CAA8B;4BACtC,eAAe;wBACjB,CAAC;oBACH;oBAEA,OAAO;wBAAE,MAAM;wBAAU;oBAAS;gBACpC;YAEA,KAAK;gBAAe;oBAClB,MAAM,uMAAIA,gCAAAA,CAA8B;wBACtC,eAAe;oBACjB,CAAC;gBACH;YAEA,KAAK;gBAAe;oBAClB,MAAM,uMAAIA,gCAAAA,CAA8B;wBACtC,eAAe;oBACjB,CAAC;gBACH;YAEA;gBAAS;oBACP,MAAM,mBAA0B;oBAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;gBACzD;QACF;IACF;IAEA,MAAM,WACJ,OAAA,EAC6D;QArLjE,IAAA,IAAA,IAAA,IAAA;QAsLI,MAAM,EAAE,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,IAAA,CAAK,OAAA,CAAQ,OAAO;QAE/C,MAAM,EAAE,eAAA,EAAiB,OAAO,QAAA,CAAS,CAAA,GAAI,sNAAMC,gBAAAA,EAAc;YAC/D,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,SAASC,iOAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D,MAAM;YACN,uBAAuB,IAAA,CAAK,qBAAA;YAC5B,+BAA2BC,wOAAAA,EACzB;YAEF,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,MAAM,EAAE,QAAQ,SAAA,EAAW,GAAG,YAAY,CAAA,GAAI;QAC9C,MAAM,SAAS,SAAS,OAAA,CAAQ,CAAC,CAAA;QAEjC,OAAO;YACL,MAAM,OAAO,IAAA;YACb,OAAO;gBACL,cAAA,CAAc,KAAA,CAAA,KAAA,SAAS,KAAA,KAAT,OAAA,KAAA,IAAA,GAAgB,aAAA,KAAhB,OAAA,KAAiC;gBAC/C,kBAAA,CAAkB,KAAA,CAAA,KAAA,SAAS,KAAA,KAAT,OAAA,KAAA,IAAA,GAAgB,iBAAA,KAAhB,OAAA,KAAqC;YACzD;YACA,cAAc,gCAAgC,OAAO,aAAa;YAClE,SAAS;gBAAE;gBAAW;YAAY;YAClC,aAAa;gBAAE,SAAS;YAAgB;YACxC,UAAU,oBAAoB,QAAQ;YACtC;YACA,SAAS;gBAAE,MAAM,KAAK,SAAA,CAAU,IAAI;YAAE;QACxC;IACF;IAEA,MAAM,SACJ,OAAA,EAC2D;QAC3D,MAAM,EAAE,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,IAAA,CAAK,OAAA,CAAQ,OAAO;QAE/C,MAAM,OAAO;YACX,GAAG,IAAA;YACH,QAAQ;QACV;QAEA,MAAM,EAAE,eAAA,EAAiB,OAAO,QAAA,CAAS,CAAA,GAAI,sNAAMF,gBAAAA,EAAc;YAC/D,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,yNAASC,iBAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D;YACA,uBAAuB,IAAA,CAAK,qBAAA;YAC5B,2OAA2BE,mCAAAA,EACzB,IAAA,CAAK,WAAA;YAEP,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,MAAM,EAAE,QAAQ,SAAA,EAAW,GAAG,YAAY,CAAA,GAAI;QAE9C,IAAI,eAA4C;QAChD,IAAI,QAA4D;YAC9D,cAAc,OAAO,GAAA;YACrB,kBAAkB,OAAO,GAAA;QAC3B;QACA,IAAI,eAAe;QAEnB,OAAO;YACL,QAAQ,SAAS,WAAA,CACf,IAAI,gBAGF;gBACA,WAAU,KAAA,EAAO,UAAA,EAAY;oBAE3B,IAAI,CAAC,MAAM,OAAA,EAAS;wBAClB,eAAe;wBACf,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO,MAAM,KAAA;wBAAM,CAAC;wBACxD;oBACF;oBAEA,MAAM,QAAQ,MAAM,KAAA;oBAGpB,IAAI,WAAW,OAAO;wBACpB,eAAe;wBACf,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO,MAAM,KAAA;wBAAM,CAAC;wBACxD;oBACF;oBAEA,IAAI,cAAc;wBAChB,eAAe;wBAEf,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,GAAG,oBAAoB,KAAK,CAAA;wBAC9B,CAAC;oBACH;oBAEA,IAAI,MAAM,KAAA,IAAS,MAAM;wBACvB,QAAQ;4BACN,cAAc,MAAM,KAAA,CAAM,aAAA;4BAC1B,kBAAkB,MAAM,KAAA,CAAM,iBAAA;wBAChC;oBACF;oBAEA,MAAM,SAAS,MAAM,OAAA,CAAQ,CAAC,CAAA;oBAE9B,IAAA,CAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,aAAA,KAAiB,MAAM;wBACjC,eAAe,gCACb,OAAO,aAAA;oBAEX;oBAEA,IAAA,CAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,IAAA,KAAQ,MAAM;wBACxB,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,WAAW,OAAO,IAAA;wBACpB,CAAC;oBACH;gBACF;gBAEA,OAAM,UAAA,EAAY;oBAChB,WAAW,OAAA,CAAQ;wBACjB,MAAM;wBACN;wBACA;oBACF,CAAC;gBACH;YACF,CAAC;YAEH,SAAS;gBAAE;gBAAW;YAAY;YAClC,aAAa;gBAAE,SAAS;YAAgB;YACxC;YACA,SAAS;gBAAE,MAAM,KAAK,SAAA,CAAU,IAAI;YAAE;QACxC;IACF;AACF;AAIA,IAAM,mLAA2CC,IAAAA,CAAE,MAAA,CAAO;IACxD,4IAAIA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACvB,iJAASA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC5B,+IAAOA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC1B,iJAASA,IAAAA,CAAE,KAAA,yIACTA,IAAAA,CAAE,MAAA,CAAO;QACP,8IAAMA,IAAAA,CAAE,MAAA,CAAO;QACf,uJAAeA,IAAAA,CAAE,MAAA,CAAO;IAC1B,CAAC;IAEH,+IAAOA,IAAAA,CACJ,MAAA,CAAO;QACN,uJAAeA,IAAAA,CAAE,MAAA,CAAO;QACxB,2JAAmBA,IAAAA,CAAE,MAAA,CAAO;IAC9B,CAAC,EACA,OAAA,CAAQ;AACb,CAAC;AAID,IAAM,8CAA8C,CAGlD,sJAEAA,IAAAA,CAAE,KAAA,CAAM;gJACNA,IAAAA,CAAE,MAAA,CAAO;YACP,2IAAIA,KAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YACvB,iJAASA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC5B,+IAAOA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC1B,iJAASA,IAAAA,CAAE,KAAA,yIACTA,IAAAA,CAAE,MAAA,CAAO;gBACP,8IAAMA,IAAAA,CAAE,MAAA,CAAO;gBACf,uJAAeA,IAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;gBAClC,+IAAOA,IAAAA,CAAE,MAAA,CAAO;YAClB,CAAC;YAEH,OAAOA,4IAAAA,CACJ,MAAA,CAAO;gBACN,uJAAeA,IAAAA,CAAE,MAAA,CAAO;gBACxB,2JAAmBA,IAAAA,CAAE,MAAA,CAAO;YAC9B,CAAC,EACA,OAAA,CAAQ;QACb,CAAC;QACD;KACD;;;;AE3UI,IAAM,iCAAN,MAEP;IAmBE,YACE,OAAA,EACA,QAAA,EACA,MAAA,CACA;QAtBF,IAAA,CAAS,oBAAA,GAAuB;QAuB9B,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,MAAA,GAAS;IAChB;IApBA,IAAI,WAAmB;QACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA;IACrB;IAEA,IAAI,uBAA+B;QApDrC,IAAA;QAqDI,OAAA,CAAO,KAAA,IAAA,CAAK,MAAA,CAAO,oBAAA,KAAZ,OAAA,KAAoC;IAC7C;IAEA,IAAI,wBAAiC;QAxDvC,IAAA;QAyDI,OAAA,CAAO,KAAA,IAAA,CAAK,MAAA,CAAO,qBAAA,KAAZ,OAAA,KAAqC;IAC9C;IAYA,MAAM,QAAQ,EACZ,MAAA,EACA,OAAA,EACA,WAAA,EACF,EAEE;QA5EJ,IAAA;QA6EI,IAAI,OAAO,MAAA,GAAS,IAAA,CAAK,oBAAA,EAAsB;YAC7C,MAAM,uMAAI,qCAAA,CAAmC;gBAC3C,UAAU,IAAA,CAAK,QAAA;gBACf,SAAS,IAAA,CAAK,OAAA;gBACd,sBAAsB,IAAA,CAAK,oBAAA;gBAC3B;YACF,CAAC;QACH;QAEA,MAAM,EAAE,eAAA,EAAiB,OAAO,QAAA,CAAS,CAAA,GAAI,MAAMM,gOAAAA,EAAc;YAC/D,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,yNAASC,iBAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,OAAO;YACtD,MAAM;gBACJ,OAAO,IAAA,CAAK,OAAA;gBACZ,OAAO;gBACP,iBAAiB;gBACjB,YAAY,IAAA,CAAK,QAAA,CAAS,UAAA;gBAC1B,MAAM,IAAA,CAAK,QAAA,CAAS,IAAA;YACtB;YACA,uBAAuBC,iPAAAA,EAAA,CACrB,KAAA,IAAA,CAAK,MAAA,CAAO,cAAA,KAAZ,OAAA,KAA8B;YAEhC,2OAA2BC,4BAAAA,EACzB;YAEF;YACA,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,OAAO;YACL,YAAY,SAAS,IAAA,CAAK,GAAA,CAAI,CAAA,OAAQ,KAAK,SAAS;YACpD,OAAO,SAAS,KAAA,GACZ;gBAAE,QAAQ,SAAS,KAAA,CAAM,aAAA;YAAc,IACvC,KAAA;YACJ,aAAa;gBAAE,SAAS;YAAgB;QAC1C;IACF;AACF;AAIA,IAAM,4KAAoCC,IAAAA,CAAE,MAAA,CAAO;IACjD,MAAMA,4IAAAA,CAAE,KAAA,yIAAMA,IAAAA,CAAE,MAAA,CAAO;QAAE,mJAAWA,IAAAA,CAAE,KAAA,CAAMA,4IAAAA,CAAE,MAAA,CAAO,CAAC;IAAE,CAAC,CAAC;IAC1D,+IAAOA,IAAAA,CAAE,MAAA,CAAO;QAAE,uJAAeA,IAAAA,CAAE,MAAA,CAAO;IAAE,CAAC,EAAE,OAAA,CAAQ;AACzD,CAAC;;ACzCM,SAAS,uBAKd,OAAA,EAKA;IACA,MAAM,0NAAU,uBAAA,EAAqB,QAAQ,OAAO;IACpD,MAAM,eAAe,QAAQ,IAAA;IAS7B,MAAM,aAAa,IAAA,CAAO;YACxB,GAAI,QAAQ,MAAA,IAAU;gBAAE,eAAe,CAAA,OAAA,EAAU,QAAQ,MAAM,EAAA;YAAG,CAAA;YAClE,GAAG,QAAQ,OAAA;QACb,CAAA;IAEA,MAAM,uBAAuB,CAAC,YAAA,CAA0C;YACtE,UAAU,GAAG,YAAY,CAAA,CAAA,EAAI,SAAS,EAAA;YACtC,KAAK,CAAC,EAAE,IAAA,CAAK,CAAA,KAAM;gBACjB,MAAM,MAAM,IAAI,IAAI,GAAG,OAAO,GAAG,IAAI,EAAE;gBACvC,IAAI,QAAQ,WAAA,EAAa;oBACvB,IAAI,MAAA,GAAS,IAAI,gBAAgB,QAAQ,WAAW,EAAE,QAAA,CAAS;gBACjE;gBACA,OAAO,IAAI,QAAA,CAAS;YACtB;YACA,SAAS;YACT,OAAO,QAAQ,KAAA;QACjB,CAAA;IAEA,MAAM,sBAAsB,CAC1B,SACA,WAAyC,CAAC,CAAA,GACvC,gBAAgB,SAAS,QAAQ;IAEtC,MAAM,kBAAkB,CACtB,SACA,WAAyC,CAAC,CAAA,GAE1C,IAAI,kCAAkC,SAAS,UAAU;YACvD,GAAG,qBAAqB,MAAM,CAAA;YAC9B,6BAA6B;QAC/B,CAAC;IAEH,MAAM,wBAAwB,CAC5B,SACA,WAA+C,CAAC,CAAA,GAEhD,IAAI,wCACF,SACA,UACA,qBAAqB,YAAY;IAGrC,MAAM,uBAAuB,CAC3B,SACA,WAA8C,CAAC,CAAA,GAE/C,IAAI,+BACF,SACA,UACA,qBAAqB,WAAW;IAGpC,MAAM,WAAW,CACf,SACA,WACG,oBAAoB,SAAS,QAAQ;IAE1C,SAAS,aAAA,GAAgB;IACzB,SAAS,SAAA,GAAY;IACrB,SAAS,eAAA,GAAkB;IAC3B,SAAS,kBAAA,GAAqB;IAE9B,OAAO;AAKT","ignoreList":[0,1,2,3,4,5,6,7,8,9],"debugId":null}},
    {"offset": {"line": 2433, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}}]
}